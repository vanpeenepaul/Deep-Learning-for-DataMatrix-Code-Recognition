{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d731594531b095d6",
   "metadata": {},
   "source": [
    "At this stage, you have a dataset with 6 folders, each containing images and their annotations in COCO format.\n",
    "\n",
    "In this notebook, we will apply visual transformations to enrich our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from nacl.pwhash.argon2id import verify\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from scipy.ndimage import map_coordinates\n",
    "from noise import pnoise2\n",
    "import math\n",
    "import random\n",
    "import albumentations as A\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import map_coordinates\n",
    "import random\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905153074ad5856",
   "metadata": {},
   "source": [
    "As always, we implement a class to handle annotations in COCO format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83616f104c4db2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, coco_json, img_dir, img_list=None, transform=None, sigma=2, target_size=(512,512)):\n",
    "        with open(coco_json, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.sigma = sigma\n",
    "        self.target_size = target_size\n",
    "\n",
    "        \n",
    "        self.liste_id = {ann['id'] for ann in self.coco_data['annotations']}\n",
    "\n",
    "       \n",
    "        self.id_to_image_id = {ann['id']: ann['image_id'] for ann in self.coco_data['annotations']}\n",
    "\n",
    "        \n",
    "        self.img_id_to_file = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
    "\n",
    "        \n",
    "        self.id_to_keypoints = {ann['id']: ann['keypoints'] for ann in self.coco_data['annotations']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a5338a504632e",
   "metadata": {},
   "source": [
    "As a first step, if you consider your dataset to be small, you can initially apply these next two cells,\n",
    "which will multiply your dataset size by 4 by applying rotations, contrast variations,\n",
    "and noise to both images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b89297ea0447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image_path, kp_v, kp_xy, transform):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        img_h, img_w = image.shape[:2]\n",
    "\n",
    "        augmented = transform(image=image, keypoints=kp_xy)\n",
    "        kps_aug_xy = augmented['keypoints']\n",
    "\n",
    "        transformed_kps = []\n",
    "        for i in range(len(kp_v)):\n",
    "            if i < len(kps_aug_xy):\n",
    "                x, y = kps_aug_xy[i]\n",
    "                v = kp_v[i]\n",
    "\n",
    "                if 0 <= x < img_w and 0 <= y < img_h and v > 0:\n",
    "                    transformed_kps.extend([float(x), float(y), int(v)])\n",
    "                else:\n",
    "                    transformed_kps.extend([float(x), float(y), 0])\n",
    "            else:\n",
    "                transformed_kps.extend([0.0, 0.0, 0])\n",
    "\n",
    "        return augmented['image'], transformed_kps\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def verify_keypoints(keypoints, img_width, img_height):\n",
    "    validated = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i:i+3]\n",
    "        if 0 <= x < img_width and 0 <= y < img_height and v > 0:\n",
    "            validated.extend([x, y, v])\n",
    "        else:\n",
    "            validated.extend([x, y, 0])\n",
    "    return validated\n",
    "\n",
    "def count_visible_keypoints(keypoints):\n",
    "    return len([v for i, v in enumerate(keypoints) if i % 3 == 2 and v > 0])\n",
    "\n",
    "\n",
    "transfos = {\n",
    "    \"rot1\": A.Compose([A.Rotate(limit=(0, 90), p=1)], keypoint_params=A.KeypointParams(format='xy')),\n",
    "    \"rot2\": A.Compose([A.Rotate(limit=(0, 90), p=1)], keypoint_params=A.KeypointParams(format='xy')),\n",
    "\n",
    "    \"noise\": A.Compose([A.GaussNoise(var_limit=(10.0, 50.0), p=1)]),\n",
    "\n",
    "    \"contrast\": A.Compose([\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.3,\n",
    "        contrast_limit=0.15,\n",
    "        p=1.0\n",
    "    )\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d5b49352f29e4",
   "metadata": {},
   "source": [
    "Please fill in \"big_dataset = \" by specifying the path to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b30ae1440c0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset = '../DATASET_TRANSFO_rot'\n",
    "\n",
    "for element in os.listdir(big_dataset):\n",
    "    if element.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    dataset = os.path.join(big_dataset, element)\n",
    "    annotations_path = os.path.join(dataset, 'annotations.json')\n",
    "\n",
    "    if not os.path.exists(annotations_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(annotations_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        X = KeypointDataset(coco_json=annotations_path, img_dir=dataset)\n",
    "        liste_identifiants = X.liste_id\n",
    "\n",
    "        if not liste_identifiants:\n",
    "            continue\n",
    "\n",
    "        new_image_id = max([img['id'] for img in data.get('images', [])], default=0)\n",
    "        new_ann_id = max([ann['id'] for ann in data.get('annotations', [])], default=0)\n",
    "\n",
    "        for id in liste_identifiants:\n",
    "            try:\n",
    "                id_image = X.id_to_image_id[id]\n",
    "                image_name = X.img_id_to_file[id_image]\n",
    "                keypoints = X.id_to_keypoints[id]\n",
    "                full_image_name = os.path.join(dataset, image_name)\n",
    "\n",
    "                if not os.path.exists(full_image_name):\n",
    "                    continue\n",
    "\n",
    "                keypoints_x = keypoints[::3]\n",
    "                keypoints_y = keypoints[1::3]\n",
    "                keypoints_v = keypoints[2::3]\n",
    "                keypoints_xy = list(zip(keypoints_x, keypoints_y))\n",
    "\n",
    "                for name, transform in transfos.items():\n",
    "                    try:\n",
    "                        new_image_id += 1\n",
    "                        new_ann_id += 1\n",
    "\n",
    "                        img_aug, kps_aug = apply_transformation(\n",
    "                            full_image_name,\n",
    "                            keypoints_v,\n",
    "                            keypoints_xy,\n",
    "                            transform\n",
    "                        )\n",
    "\n",
    "                        kps_aug = verify_keypoints(kps_aug, 512, 512)\n",
    "\n",
    "                        if img_aug.dtype != np.uint8:\n",
    "                            if img_aug.max() <= 1.0:\n",
    "                                img_aug = (img_aug * 255).clip(0, 255).astype(np.uint8)\n",
    "                            else:\n",
    "                                img_aug = img_aug.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "                        img_aug_bgr = cv2.cvtColor(img_aug, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                        base_name, ext = os.path.splitext(image_name)\n",
    "                        filename_image_transformed = f\"{name}_{base_name}{ext}\"\n",
    "                        chemin_sortie = os.path.join(dataset, filename_image_transformed)\n",
    "                        num_keypoints = len(kps_aug)//3\n",
    "\n",
    "                       \n",
    "                        x_coords = kps_aug[::3]\n",
    "                        y_coords = kps_aug[1::3]\n",
    "                        x_max, x_min = max(x_coords), min(x_coords)\n",
    "                        y_max, y_min = max(y_coords), min(y_coords)\n",
    "                        area = (y_max - y_min) * (x_max - x_min)\n",
    "\n",
    "                        success = cv2.imwrite(chemin_sortie, img_aug_bgr)\n",
    "                        if not success:\n",
    "                            continue\n",
    "\n",
    "                        data['images'].append({\n",
    "                            \"id\": new_image_id,\n",
    "                            \"file_name\": filename_image_transformed,\n",
    "                            \"width\": 512,\n",
    "                            \"height\": 512\n",
    "                        })\n",
    "\n",
    "                        data['annotations'].append({\n",
    "                            \"id\": new_ann_id,\n",
    "                            \"image_id\": new_image_id,\n",
    "                            \"category_id\": 1,  \n",
    "                            \"keypoints\": kps_aug,\n",
    "                            \"num_keypoints\": num_keypoints,  \n",
    "                            \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],  \n",
    "                            \"area\": area,  \n",
    "                            \"iscrowd\": 0,\n",
    "                            \"segmentation\": []\n",
    "                        })\n",
    "\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with open(annotations_path, 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fb8fd7cc28e34",
   "metadata": {},
   "source": [
    "Now we will apply 2 different transformations to all images and annotations in our dataset,\n",
    "one reproducing the curvature of a datamatrix code, the other the crumpling of a datamatrix code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b26bcb2e3d5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_keypoints(kp):\n",
    "    x_black, y_black, x_white, y_white = [], [], [], []\n",
    "    for i in range(0, len(kp), 3):\n",
    "        if kp[i + 2] == 2:\n",
    "            x_black.append(kp[i])\n",
    "            y_black.append(kp[i + 1])\n",
    "        else:\n",
    "            x_white.append(kp[i])\n",
    "            y_white.append(kp[i + 1])\n",
    "    return x_black, y_black, x_white, y_white\n",
    "\n",
    "def validate_keypoints(keypoints, width, height):\n",
    "    \"\"\"Validate and correct keypoints so they remain within image boundaries\"\"\"\n",
    "    validated_keypoints = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i], keypoints[i + 1], keypoints[i + 2]\n",
    "        if v > 0:\n",
    "            x = max(0, min(width - 1, x))\n",
    "            y = max(0, min(height - 1, y))\n",
    "        validated_keypoints.extend([x, y, v])\n",
    "    return validated_keypoints\n",
    "\n",
    "\n",
    "def calculate_bbox_from_keypoints(keypoints):\n",
    "    \"\"\"Calculate the bounding box from visible keypoints\"\"\"\n",
    "    if not keypoints:\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    visible_points = [(keypoints[i], keypoints[i+1]) for i in range(0, len(keypoints), 3) if keypoints[i+2] > 0]\n",
    "    if not visible_points:\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    x_coords, y_coords = zip(*visible_points)\n",
    "    x_max, x_min = max(x_coords), min(x_coords)\n",
    "    y_max, y_min = max(y_coords), min(y_coords)\n",
    "    area = (y_max - y_min) * (x_max - x_min)\n",
    "\n",
    "    return x_min, y_min, x_max, y_max, area\n",
    "\n",
    "\n",
    "def save_transformed_image(img_aug, dataset, filename):\n",
    "    \"\"\"Save the transformed image\"\"\"\n",
    "    if img_aug.dtype != np.uint8:\n",
    "        if img_aug.max() <= 1.0:\n",
    "            img_aug = (img_aug * 255).clip(0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_aug = img_aug.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    img_aug_bgr = cv2.cvtColor(img_aug, cv2.COLOR_RGB2BGR)\n",
    "    chemin_sortie = os.path.join(dataset, filename)\n",
    "    success = cv2.imwrite(chemin_sortie, img_aug_bgr)\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Erreur lors de l'écriture de l'image: {chemin_sortie}\")\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e0b36cbb9a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_curvature_transform(image, curvature_factor=0.3):\n",
    "    height, width = image.shape[:2]\n",
    "    y_dest, x_dest = np.mgrid[0:height, 0:width]\n",
    "    x_source = x_dest - curvature_factor * np.sin(2 * np.pi * y_dest / height) * width\n",
    "    y_source = y_dest.astype(float)\n",
    "\n",
    "    result = np.zeros_like(image)\n",
    "    for c in range(image.shape[2]):\n",
    "        result[..., c] = map_coordinates(image[..., c], [y_source, x_source], order=1, mode='constant', cval=255)\n",
    "\n",
    "    return result.astype(np.uint8), x_source, y_source\n",
    "\n",
    "\n",
    "def deform_point(x, y, height, width, curvature_factor=0.3):\n",
    "    delta_x = curvature_factor * np.sin(2 * np.pi * y / height) * width\n",
    "    x_deformed = x + delta_x\n",
    "\n",
    "    \n",
    "    x_deformed = np.clip(x_deformed, 0, width - 1)\n",
    "    y = np.clip(y, 0, height - 1)\n",
    "\n",
    "    return x_deformed, y\n",
    "\n",
    "\n",
    "def deform_keypoints(keypoints, height, width, curvature_factor=0.3):\n",
    "    new_keypoints = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i], keypoints[i + 1], keypoints[i + 2]\n",
    "        if v > 0:\n",
    "            x_def, y_def = deform_point(x, y, height, width, curvature_factor)\n",
    "            new_keypoints.extend([x_def, y_def, v])\n",
    "        else:\n",
    "            new_keypoints.extend([x, y, v])\n",
    "    return new_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59574a08529bd962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wrinkle_points(width, height, num_wrinkles=3, min_distance=80):\n",
    "    \"\"\"Generate randomly distributed crumpling\"\"\"\n",
    "    wrinkle_points = []\n",
    "    attempts = 0\n",
    "    max_attempts = 1000\n",
    "\n",
    "    while len(wrinkle_points) < num_wrinkles and attempts < max_attempts:\n",
    "        x = random.uniform(width * 0.2, width * 0.8)\n",
    "        y = random.uniform(height * 0.2, height * 0.8)\n",
    "\n",
    "        valid = True\n",
    "        for px, py, _, _ in wrinkle_points:\n",
    "            if np.sqrt((x - px)**2 + (y - py)**2) < min_distance:\n",
    "                valid = False\n",
    "                break\n",
    "\n",
    "        if valid:\n",
    "            intensity = random.uniform(3, 8)\n",
    "            radius = random.uniform(40, 80)\n",
    "            wrinkle_points.append((x, y, intensity, radius))\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    return wrinkle_points\n",
    "\n",
    "\n",
    "def apply_wrinkle_transform(image, wrinkle_intensity=0.3, num_wrinkles=3):\n",
    "    \"\"\"Apply a realistic crumpling transformation to an image\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    wrinkle_points = generate_wrinkle_points(width, height, num_wrinkles)\n",
    "\n",
    "    y_dest, x_dest = np.mgrid[0:height, 0:width]\n",
    "    x_source = x_dest.astype(float)\n",
    "    y_source = y_dest.astype(float)\n",
    "\n",
    "    for wx, wy, intensity, radius in wrinkle_points:\n",
    "        dist = np.sqrt((x_dest - wx)**2 + (y_dest - wy)**2)\n",
    "        influence = np.exp(-dist**2 / (2 * (radius * 1.5)**2))\n",
    "\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        radial_factor = intensity * wrinkle_intensity * influence\n",
    "\n",
    "        displacement_x = radial_factor * (\n",
    "            np.cos(angle + dist / radius) * np.sin(dist / radius * 2) +\n",
    "            0.2 * np.sin(2 * angle) * np.exp(-dist / (radius * 0.8))\n",
    "        )\n",
    "\n",
    "        displacement_y = radial_factor * (\n",
    "            np.sin(angle + dist / radius) * np.sin(dist / radius * 2) +\n",
    "            0.2 * np.cos(2 * angle) * np.exp(-dist / (radius * 0.8))\n",
    "        )\n",
    "\n",
    "        x_source += displacement_x\n",
    "        y_source += displacement_y\n",
    "\n",
    "    result = np.zeros_like(image)\n",
    "    for c in range(image.shape[2]):\n",
    "        result[..., c] = map_coordinates(\n",
    "            image[..., c], [y_source, x_source], order=1, mode='constant', cval=255\n",
    "        )\n",
    "\n",
    "    displacement_x = x_source - x_dest\n",
    "    displacement_y = y_source - y_dest\n",
    "\n",
    "    return result.astype(np.uint8), displacement_x, displacement_y\n",
    "\n",
    "\n",
    "def deform_point_wrinkle(x, y, displacement_x, displacement_y, width, height):\n",
    "    \"\"\"Apply crumpling deformation to a point\"\"\"\n",
    "    x = np.clip(x, 0, width - 1)\n",
    "    y = np.clip(y, 0, height - 1)\n",
    "\n",
    "    x_int, y_int = int(x), int(y)\n",
    "    x_frac, y_frac = x - x_int, y - y_int\n",
    "\n",
    "    x_int = min(x_int, displacement_x.shape[1] - 1)\n",
    "    y_int = min(y_int, displacement_x.shape[0] - 1)\n",
    "\n",
    "    if x_int < displacement_x.shape[1] - 1 and y_int < displacement_x.shape[0] - 1:\n",
    "        dx_00 = displacement_x[y_int, x_int]\n",
    "        dx_01 = displacement_x[y_int, x_int + 1]\n",
    "        dx_10 = displacement_x[y_int + 1, x_int]\n",
    "        dx_11 = displacement_x[y_int + 1, x_int + 1]\n",
    "\n",
    "        dy_00 = displacement_y[y_int, x_int]\n",
    "        dy_01 = displacement_y[y_int, x_int + 1]\n",
    "        dy_10 = displacement_y[y_int + 1, x_int]\n",
    "        dy_11 = displacement_y[y_int + 1, x_int + 1]\n",
    "\n",
    "        dx = (dx_00 * (1 - x_frac) * (1 - y_frac) +\n",
    "              dx_01 * x_frac * (1 - y_frac) +\n",
    "              dx_10 * (1 - x_frac) * y_frac +\n",
    "              dx_11 * x_frac * y_frac)\n",
    "\n",
    "        dy = (dy_00 * (1 - x_frac) * (1 - y_frac) +\n",
    "              dy_01 * x_frac * (1 - y_frac) +\n",
    "              dy_10 * (1 - x_frac) * y_frac +\n",
    "              dy_11 * x_frac * y_frac)\n",
    "    else:\n",
    "        dx = displacement_x[y_int, x_int]\n",
    "        dy = displacement_y[y_int, x_int]\n",
    "\n",
    "    x_deformed = x + dx\n",
    "    y_deformed = y + dy\n",
    "\n",
    "    x_deformed = np.clip(x_deformed, 0, width - 1)\n",
    "    y_deformed = np.clip(y_deformed, 0, height - 1)\n",
    "\n",
    "    return x_deformed, y_deformed\n",
    "\n",
    "\n",
    "def deform_keypoints_wrinkle(keypoints, displacement_x, displacement_y, width, height):\n",
    "    \"\"\"Apply crumpling transformation to keypoints\"\"\"\n",
    "    new_keypoints = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i], keypoints[i + 1], keypoints[i + 2]\n",
    "        if v > 0:\n",
    "            x_def, y_def = deform_point_wrinkle(x, y, displacement_x, displacement_y, width, height)\n",
    "            new_keypoints.extend([x_def, y_def, v])\n",
    "        else:\n",
    "            new_keypoints.extend([x, y, v])\n",
    "    return new_keypoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77ecf95e2c74be",
   "metadata": {},
   "source": [
    "Please fill in \"big_dataset = \" by specifying the path to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271fed0fce98fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset = 'DATASET'\n",
    "\n",
    "for element in os.listdir(big_dataset):\n",
    "    if element.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    dataset = os.path.join(big_dataset, element)\n",
    "    annotations_path = os.path.join(dataset, 'annotations.json')\n",
    "\n",
    "    if not os.path.exists(annotations_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(annotations_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        X = KeypointDataset(coco_json=annotations_path, img_dir=dataset)\n",
    "        liste_identifiants = X.liste_id\n",
    "\n",
    "        if not liste_identifiants:\n",
    "            continue\n",
    "\n",
    "       \n",
    "        new_image_id = max([img['id'] for img in data.get('images', [])], default=0)\n",
    "        new_ann_id = max([ann['id'] for ann in data.get('annotations', [])], default=0)\n",
    "\n",
    "        for id in liste_identifiants:\n",
    "            try:\n",
    "                id_image = X.id_to_image_id[id]\n",
    "                image_name = X.img_id_to_file[id_image]\n",
    "                keypoints = X.id_to_keypoints[id]\n",
    "                full_image_name = os.path.join(dataset, image_name)\n",
    "\n",
    "                if not os.path.exists(full_image_name):\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                img = Image.open(full_image_name).convert(\"RGB\")\n",
    "                img_np = np.array(img)\n",
    "                base_name, ext = os.path.splitext(image_name)\n",
    "\n",
    "                \n",
    "                new_image_id += 1\n",
    "                new_ann_id += 1\n",
    "\n",
    "                \n",
    "                curvature = 0.2\n",
    "\n",
    "                \n",
    "                img_curved, x_source, y_source = apply_curvature_transform(img_np, curvature)\n",
    "                kps_curved = deform_keypoints(keypoints, img_np.shape[0], img_np.shape[1], curvature)\n",
    "                kps_curved = validate_keypoints(kps_curved, 512, 512)\n",
    "\n",
    "                \n",
    "                filename_curved = f\"curved_{base_name}{ext}\"\n",
    "                if save_transformed_image(img_curved, dataset, filename_curved):\n",
    "                    \n",
    "                    num_keypoints_curved = len([v for v in kps_curved[2::3] if v > 0])\n",
    "                    x_min, y_min, x_max, y_max, area = calculate_bbox_from_keypoints(kps_curved)\n",
    "\n",
    "                   \n",
    "                    data['images'].append({\n",
    "                        \"id\": new_image_id,\n",
    "                        \"file_name\": filename_curved,\n",
    "                        \"width\": 512,\n",
    "                        \"height\": 512\n",
    "                    })\n",
    "\n",
    "                    data['annotations'].append({\n",
    "                        \"id\": new_ann_id,\n",
    "                        \"image_id\": new_image_id,\n",
    "                        \"category_id\": 1,\n",
    "                        \"keypoints\": kps_curved,\n",
    "                        \"num_keypoints\": num_keypoints_curved,\n",
    "                        \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                        \"area\": area,\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"segmentation\": []\n",
    "                    })\n",
    "\n",
    "                \n",
    "                new_image_id += 1\n",
    "                new_ann_id += 1\n",
    "\n",
    "                \n",
    "                wrinkle_intensity = 0.3\n",
    "                num_wrinkles = 3 \n",
    "\n",
    "                \n",
    "                img_wrinkled, displacement_x, displacement_y = apply_wrinkle_transform(\n",
    "                    img_np, wrinkle_intensity, num_wrinkles\n",
    "                )\n",
    "                kps_wrinkled = deform_keypoints_wrinkle(\n",
    "                    keypoints, displacement_x, displacement_y, img_np.shape[1], img_np.shape[0]\n",
    "                )\n",
    "                kps_wrinkled = validate_keypoints(kps_wrinkled, 512, 512)\n",
    "\n",
    "                \n",
    "                filename_wrinkled = f\"crumpling_{base_name}{ext}\"\n",
    "                if save_transformed_image(img_wrinkled, dataset, filename_wrinkled):\n",
    "                    \n",
    "                    num_keypoints_wrinkled = len([v for v in kps_wrinkled[2::3] if v > 0])\n",
    "                    x_min, y_min, x_max, y_max, area = calculate_bbox_from_keypoints(kps_wrinkled)\n",
    "\n",
    "                    \n",
    "                    data['images'].append({\n",
    "                        \"id\": new_image_id,\n",
    "                        \"file_name\": filename_wrinkled,\n",
    "                        \"width\": 512,\n",
    "                        \"height\": 512\n",
    "                    })\n",
    "\n",
    "                    data['annotations'].append({\n",
    "                        \"id\": new_ann_id,\n",
    "                        \"image_id\": new_image_id,\n",
    "                        \"category_id\": 1,\n",
    "                        \"keypoints\": kps_wrinkled,\n",
    "                        \"num_keypoints\": num_keypoints_wrinkled,\n",
    "                        \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                        \"area\": area,\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"segmentation\": []\n",
    "                    })\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors du traitement de l'ID {id}: {e}\")\n",
    "                continue\n",
    "\n",
    "       \n",
    "        with open(annotations_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement du dataset {dataset}: {e}\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564238ad252cb8a",
   "metadata": {},
   "source": [
    "You now have a dataset of the same format but containing more data, having applied transformations to your initial images and annotations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
