{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5776aa685fb0723b",
   "metadata": {},
   "source": [
    "At this stage, you have a complete dataset of images and annotations tailored to our study, so now let’s develop a training script for an AI model to detect data matrix code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063d32b50886c76",
   "metadata": {},
   "source": [
    "To better understand the design of our model’s architecture, I strongly encourage you to refer to section 'x' of my report 'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec50bbb305c03dc",
   "metadata": {},
   "source": [
    "Let’s start by loading all the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.187337Z",
     "start_time": "2025-09-03T01:11:10.803434Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "import argparse\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage import maximum_filter\n",
    "from sklearn.metrics import average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b41b4f0414163",
   "metadata": {},
   "source": [
    "Let's define the class that will let us handle our data (annotations and images), build heatmaps, and apply visual transformations so that, at each epoch, the images and annotations seen by our model are never the same—thus limiting the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b666a16dbaa631d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.240161Z",
     "start_time": "2025-09-03T01:11:13.218435Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeypointDatasetAugmented(Dataset):\n",
    "    def __init__(self, coco_json, img_dir, img_list=None, sigma=2, target_size=(512, 512),\n",
    "                 augment=True, augment_prob=0.8, unified_cells=False):\n",
    "\n",
    "        with open(coco_json, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "\n",
    "        self._clean_invalid_keypoints()\n",
    "        self.img_dir = img_dir\n",
    "        self.sigma = sigma\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.augment_prob = augment_prob\n",
    "        self.unified_cells = unified_cells\n",
    "\n",
    "\n",
    "        self.id_list = {ann['id'] for ann in self.coco_data['annotations']}\n",
    "        self.id_to_image_id = {ann['id']: ann['image_id'] for ann in self.coco_data['annotations']}\n",
    "        self.img_id_to_file = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
    "        self.id_to_keypoints = {ann['id']: ann['keypoints'] for ann in self.coco_data['annotations']}\n",
    "\n",
    "\n",
    "        self.img_to_anns = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.img_to_anns:\n",
    "                self.img_to_anns[img_id] = []\n",
    "            self.img_to_anns[img_id].append(ann)\n",
    "\n",
    "\n",
    "        if img_list:\n",
    "            self.img_ids = [\n",
    "                img_id for img_id in self.img_id_to_file\n",
    "                if self.img_id_to_file[img_id] in img_list and img_id in self.img_to_anns\n",
    "            ]\n",
    "        else:\n",
    "            self.img_ids = list(self.img_to_anns.keys())\n",
    "\n",
    "        if self.augment:\n",
    "            self.geometric_transform = A.Compose([\n",
    "                A.Rotate(limit=15, p=0.85, border_mode=cv2.BORDER_REFLECT),\n",
    "                A.HorizontalFlip(p=0.15),\n",
    "                A.VerticalFlip(p=0),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=15,\n",
    "                    border_mode=cv2.BORDER_REFLECT,\n",
    "                    p=0\n",
    "                ),\n",
    "            ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=True))\n",
    "\n",
    "            self.photometric_transform = A.Compose([\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.3,\n",
    "                    contrast_limit=0.2,\n",
    "                    p=0.7\n",
    "                ),\n",
    "                A.ColorJitter(\n",
    "                    brightness=0.2,\n",
    "                    contrast=0.2,\n",
    "                    saturation=0.2,\n",
    "                    hue=0.1,\n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=20,\n",
    "                    sat_shift_limit=30,\n",
    "                    val_shift_limit=20,\n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(p=0.3),\n",
    "                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
    "                ], p=0.4),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=3, p=0.3),\n",
    "                    A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "                ], p=0.3),\n",
    "            ])\n",
    "        else:\n",
    "            self.geometric_transform = None\n",
    "            self.photometric_transform = None\n",
    "\n",
    "    def _clean_invalid_keypoints(self):\n",
    "        cleaned_annotations = []\n",
    "        total_keypoints = 0\n",
    "        invalid_keypoints = 0\n",
    "\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            kpts = ann['keypoints']\n",
    "            cleaned_kpts = []\n",
    "\n",
    "            for i in range(0, len(kpts), 3):\n",
    "                x, y, v = kpts[i:i + 3]\n",
    "                total_keypoints += 1\n",
    "                if np.isfinite(x) and np.isfinite(y) and not (np.isnan(x) or np.isnan(y)):\n",
    "                    cleaned_kpts.extend([float(x), float(y), int(v)])\n",
    "                else:\n",
    "                    cleaned_kpts.extend([0.0, 0.0, 0])\n",
    "                    invalid_keypoints += 1\n",
    "\n",
    "            ann['keypoints'] = cleaned_kpts\n",
    "            cleaned_annotations.append(ann)\n",
    "\n",
    "        self.coco_data['annotations'] = cleaned_annotations\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def _extract_keypoints(self, annotations, original_width, original_height):\n",
    "        keypoints = []\n",
    "        keypoint_info = []\n",
    "        invalid_count = 0\n",
    "\n",
    "        for ann in annotations:\n",
    "            kpts = ann['keypoints']\n",
    "            for i in range(0, len(kpts), 3):\n",
    "                x, y, v = kpts[i:i + 3]\n",
    "\n",
    "                if not (np.isfinite(x) and np.isfinite(y)) or np.isnan(x) or np.isnan(y):\n",
    "                    invalid_count += 1\n",
    "                    continue\n",
    "\n",
    "                if v > 0:\n",
    "                    if 0 <= x < original_width and 0 <= y < original_height:\n",
    "                        keypoints.append((float(x), float(y)))\n",
    "\n",
    "                        if self.unified_cells:\n",
    "                            visibility = 1\n",
    "                        else:\n",
    "                            visibility = v\n",
    "\n",
    "                        keypoint_info.append({\n",
    "                            'visibility': visibility,\n",
    "                            'label': 1 if self.unified_cells else v\n",
    "                        })\n",
    "                    else:\n",
    "                        invalid_count += 1\n",
    "\n",
    "        return keypoints, keypoint_info\n",
    "\n",
    "    def _apply_geometric_augmentation(self, image, keypoints):\n",
    "        try:\n",
    "            if keypoints:\n",
    "                valid_keypoints = []\n",
    "                for kp in keypoints:\n",
    "                    if len(kp) >= 2 and np.isfinite(kp[0]) and np.isfinite(kp[1]):\n",
    "                        valid_keypoints.append(kp)\n",
    "\n",
    "                if valid_keypoints:\n",
    "                    transformed = self.geometric_transform(image=image, keypoints=valid_keypoints)\n",
    "                    return transformed['image'], transformed['keypoints']\n",
    "                else:\n",
    "\n",
    "                    transformed = self.geometric_transform(image=image, keypoints=[])\n",
    "                    return transformed['image'], []\n",
    "            else:\n",
    "                transformed = self.geometric_transform(image=image, keypoints=[])\n",
    "                return transformed['image'], []\n",
    "        except Exception as e:\n",
    "            return image, keypoints\n",
    "\n",
    "    def _apply_photometric_augmentation(self, image):\n",
    "        try:\n",
    "            transformed = self.photometric_transform(image=image)\n",
    "            return transformed['image']\n",
    "        except Exception as e:\n",
    "            return image\n",
    "\n",
    "    def _create_heatmaps_from_keypoints(self, keypoints, keypoint_info, width, height):\n",
    "        if self.unified_cells:\n",
    "            heatmap_unified = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "            for (x, y), info in zip(keypoints, keypoint_info):\n",
    "\n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    self._add_gaussian(heatmap_unified, x, y, self.sigma)\n",
    "\n",
    "            return heatmap_unified, np.zeros((height, width), dtype=np.float32)\n",
    "        else:\n",
    "            heatmap_black = np.zeros((height, width), dtype=np.float32)\n",
    "            heatmap_white = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "            for (x, y), info in zip(keypoints, keypoint_info):\n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    if info['visibility'] == 2:\n",
    "                        self._add_gaussian(heatmap_black, x, y, self.sigma)\n",
    "                    elif info['visibility'] == 1:\n",
    "                        self._add_gaussian(heatmap_white, x, y, self.sigma)\n",
    "\n",
    "            return heatmap_black, heatmap_white\n",
    "\n",
    "    def _add_gaussian(self, heatmap, x, y, sigma):\n",
    "        height, width = heatmap.shape\n",
    "\n",
    "\n",
    "        if not (np.isfinite(x) and np.isfinite(y)) or np.isnan(x) or np.isnan(y):\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            x, y = int(round(x)), int(round(y))\n",
    "        except (ValueError, OverflowError):\n",
    "            return\n",
    "\n",
    "        x = max(0, min(x, width - 1))\n",
    "        y = max(0, min(y, height - 1))\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        radius = int(size // 2)\n",
    "\n",
    "        x0 = int(max(0, x - radius))\n",
    "        y0 = int(max(0, y - radius))\n",
    "        x1 = int(min(width, x + radius + 1))\n",
    "        y1 = int(min(height, y + radius + 1))\n",
    "\n",
    "        xs = np.arange(x0, x1)\n",
    "        ys = np.arange(y0, y1)\n",
    "\n",
    "        if len(xs) == 0 or len(ys) == 0:\n",
    "            return\n",
    "\n",
    "        xx, yy = np.meshgrid(xs, ys)\n",
    "\n",
    "        gaussian = np.exp(-((xx - x) ** 2 + (yy - y) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "        try:\n",
    "            heatmap[y0:y1, x0:x1] = np.maximum(heatmap[y0:y1, x0:x1], gaussian)\n",
    "        except (ValueError, IndexError):\n",
    "            pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_file = self.img_id_to_file[img_id]\n",
    "        img_path = os.path.join(self.img_dir, img_file)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            original_width, original_height = image.size\n",
    "\n",
    "\n",
    "            image = image.resize(self.target_size, Image.LANCZOS)\n",
    "            image = np.array(image)\n",
    "\n",
    "            height, width = self.target_size\n",
    "            annotations = self.img_to_anns[img_id]\n",
    "\n",
    "\n",
    "            keypoints, keypoint_info = self._extract_keypoints(annotations, original_width, original_height)\n",
    "\n",
    "\n",
    "            scale_x = width / original_width\n",
    "            scale_y = height / original_height\n",
    "\n",
    "            scaled_keypoints = []\n",
    "            for x, y in keypoints:\n",
    "                new_x = x * scale_x\n",
    "                new_y = y * scale_y\n",
    "\n",
    "                if np.isfinite(new_x) and np.isfinite(new_y):\n",
    "                    scaled_keypoints.append((new_x, new_y))\n",
    "\n",
    "\n",
    "            if self.augment and random.random() < self.augment_prob:\n",
    "\n",
    "                image, scaled_keypoints = self._apply_geometric_augmentation(image, scaled_keypoints)\n",
    "\n",
    "\n",
    "                image = self._apply_photometric_augmentation(image)\n",
    "\n",
    "\n",
    "            heatmap_first, heatmap_second = self._create_heatmaps_from_keypoints(\n",
    "                scaled_keypoints, keypoint_info[:len(scaled_keypoints)], width, height\n",
    "            )\n",
    "\n",
    "            if not (np.isfinite(heatmap_first).all() and np.isfinite(heatmap_second).all()):\n",
    "                heatmap_first = np.nan_to_num(heatmap_first, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                heatmap_second = np.nan_to_num(heatmap_second, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            heatmap_first = torch.from_numpy(heatmap_first).unsqueeze(0).float()\n",
    "            heatmap_second = torch.from_numpy(heatmap_second).unsqueeze(0).float()\n",
    "\n",
    "            return image, (heatmap_first, heatmap_second)\n",
    "\n",
    "        except Exception as e:\n",
    "            height, width = self.target_size\n",
    "            empty_image = torch.zeros(3, height, width, dtype=torch.float32)\n",
    "            empty_heatmap = torch.zeros(1, height, width, dtype=torch.float32)\n",
    "            return empty_image, (empty_heatmap, empty_heatmap)\n",
    "\n",
    "    def set_augmentation(self, enabled, prob=0.8):\n",
    "        self.augment = enabled\n",
    "        self.augment_prob = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02137b2ebbe79b",
   "metadata": {},
   "source": [
    "Define the class that lets us instantiate one of the following backbones: ResNet-18, ResNet-34, or ResNet-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f542980ff665a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.298869Z",
     "start_time": "2025-09-03T01:11:13.291248Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeypointDetector(nn.Module):\n",
    "    def __init__(self, backbone='resnet18', pretrained=True, unified_cells=False):\n",
    "        super().__init__()\n",
    "        self.unified_cells = unified_cells\n",
    "\n",
    "        if backbone == 'resnet18':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "            else:\n",
    "                self.backbone = models.resnet18(weights=None)\n",
    "            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "            backbone_features = 512\n",
    "        elif backbone == 'resnet34':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "            else:\n",
    "                self.backbone = models.resnet34(weights=None)\n",
    "            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "            backbone_features = 512\n",
    "        elif backbone == 'resnet50':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "            else:\n",
    "                self.backbone = models.resnet50(weights=None)\n",
    "            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "            backbone_features = 2048\n",
    "        else:\n",
    "            raise ValueError(f\"Backbone '{backbone}' not supported.\")\n",
    "\n",
    "        output_channels = 1 if unified_cells else 2\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(backbone_features, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, output_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        heatmaps = self.upsample(features)\n",
    "        return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824a52060f84b17",
   "metadata": {},
   "source": [
    "Let’s now define all the loss functions to obtain two final losses (each combining multiple loss functions): one for training and one for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b95906e5e25763",
   "metadata": {},
   "source": [
    "The idea is to swap the training loss to optimize our model, while always keeping the same evaluation loss so we can compare performance across different training losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9246500c87c9994a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.364657Z",
     "start_time": "2025-09-03T01:11:13.348548Z"
    }
   },
   "outputs": [],
   "source": [
    "def focal_loss(pred, target, zeta=0.25, eta=2.0):\n",
    "    bce_loss = nn.functional.binary_cross_entropy(pred, target, reduction='none')\n",
    "    pt = torch.exp(-bce_loss)\n",
    "    focal_loss = zeta * (1 - pt) ** eta * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "def f(d,SIGMA):\n",
    "    return np.exp(-(d ** 2) / (2 * SIGMA ** 2))\n",
    "\n",
    "SIGMA = 2\n",
    "\n",
    "CONTRAST_BIN_THRESHOLD = f(1*SIGMA,SIGMA)\n",
    "\n",
    "\n",
    "def L_pull_torch(H: torch.Tensor, G: torch.Tensor, eps: float = EPS) -> torch.Tensor:\n",
    "    G = G.to(device=H.device, dtype=H.dtype)\n",
    "    O = torch.ones_like(G)\n",
    "\n",
    "    cells = G * H\n",
    "    none_cells = (O - G) * H\n",
    "\n",
    "    N1 = G.sum()\n",
    "    N2 = (O - G).sum()\n",
    "\n",
    "    avg_1 = cells.sum() / (N1 + eps)\n",
    "    avg_2 = none_cells.sum() / (N2 + eps)\n",
    "\n",
    "    term1 = ((cells - avg_1 * G) ** 2).sum() / (N1 + eps)\n",
    "    term2 = ((none_cells - avg_2 * (O - G)) ** 2).sum() / (N2 + eps)\n",
    "\n",
    "    return 0.5 * (term1 + term2)\n",
    "\n",
    "\n",
    "def L_push_torch(H: torch.Tensor, G: torch.Tensor, eps: float = EPS) -> torch.Tensor:\n",
    "    G = G.to(device=H.device, dtype=H.dtype)\n",
    "    O = torch.ones_like(G)\n",
    "\n",
    "    cells = G * H\n",
    "    none_cells = (O - G) * H\n",
    "\n",
    "    N1 = G.sum()\n",
    "    N2 = (O - G).sum()\n",
    "\n",
    "    avg_1 = cells.sum() / (N1 + eps)\n",
    "    avg_2 = none_cells.sum() / (N2 + eps)\n",
    "\n",
    "    mat_1 = G - (cells - avg_2 * G) ** 2\n",
    "    mat_2 = (O - G) - (none_cells - avg_1 * (O - G)) ** 2\n",
    "\n",
    "    return (F.relu(mat_1).sum() + F.relu(mat_2).sum()) / (N1 + N2 + eps)\n",
    "\n",
    "\n",
    "def contrast_loss_torch(predicted_heatmaps: torch.Tensor,\n",
    "                                     target_heatmaps,\n",
    "                                     sigma: float = 2.0,\n",
    "                                     unified_cells: bool = False):\n",
    "    batch_size = predicted_heatmaps.shape[0]\n",
    "    device = predicted_heatmaps.device\n",
    "    dtype = predicted_heatmaps.dtype\n",
    "\n",
    "    bin_thresh = CONTRAST_BIN_THRESHOLD\n",
    "\n",
    "    total_l_push = predicted_heatmaps.new_zeros(())\n",
    "    total_l_pull = predicted_heatmaps.new_zeros(())\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        if unified_cells:\n",
    "            pred = predicted_heatmaps[b, 0]\n",
    "            tgt = target_heatmaps[0][b, 0].to(device=device, dtype=dtype)\n",
    "            G = (tgt >= bin_thresh).float()\n",
    "            total_l_push = total_l_push + L_push_torch(pred, G)\n",
    "            total_l_pull = total_l_pull + L_pull_torch(pred, G)\n",
    "        else:\n",
    "            pred_b = predicted_heatmaps[b, 0]\n",
    "            pred_w = predicted_heatmaps[b, 1]\n",
    "            tgt_b = target_heatmaps[0][b, 0].to(device=device, dtype=dtype)\n",
    "            tgt_w = target_heatmaps[1][b, 0].to(device=device, dtype=dtype)\n",
    "            G_b = (tgt_b >= bin_thresh).float()\n",
    "            G_w = (tgt_w >= bin_thresh).float()\n",
    "\n",
    "            total_l_push = total_l_push + L_push_torch(pred_b, G_b) + L_push_torch(pred_w, G_w)\n",
    "            total_l_pull = total_l_pull + L_pull_torch(pred_b, G_b) + L_pull_torch(pred_w, G_w)\n",
    "\n",
    "    denom = max(1, batch_size)\n",
    "    return total_l_push / denom, total_l_pull / denom\n",
    "\n",
    "\n",
    "def mse_loss_only(outputs, targets, unified_cells=False):\n",
    "    if unified_cells:\n",
    "        heatmap_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_true = targets[0]\n",
    "        mse_loss = nn.functional.mse_loss(heatmap_pred, heatmap_true)\n",
    "        total_loss = mse_loss\n",
    "    else:\n",
    "        heatmap_black_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_white_pred = outputs[:, 1, :, :].unsqueeze(1)\n",
    "\n",
    "        heatmap_black_true = targets[0]\n",
    "        heatmap_white_true = targets[1]\n",
    "\n",
    "        mse_loss_black = nn.functional.mse_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        mse_loss_white = nn.functional.mse_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        total_loss = mse_loss_black + mse_loss_white\n",
    "\n",
    "    return total_loss, {\n",
    "        'mse_loss': total_loss.item(),\n",
    "        'focal_loss': 0.0,\n",
    "        'l_push': 0.0,\n",
    "        'l_pull': 0.0,\n",
    "        'total_loss': total_loss.item()\n",
    "    }\n",
    "\n",
    "\n",
    "def mse_focal_loss(outputs, targets, alpha=1.0, beta=0.5, unified_cells=False):\n",
    "    if unified_cells:\n",
    "        heatmap_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_true = targets[0]\n",
    "\n",
    "        mse_loss = nn.functional.mse_loss(heatmap_pred, heatmap_true)\n",
    "        focal_loss_val = focal_loss(heatmap_pred, heatmap_true)\n",
    "\n",
    "        total_loss = alpha * mse_loss + beta * focal_loss_val\n",
    "    else:\n",
    "        heatmap_black_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_white_pred = outputs[:, 1, :, :].unsqueeze(1)\n",
    "\n",
    "        heatmap_black_true = targets[0]\n",
    "        heatmap_white_true = targets[1]\n",
    "\n",
    "        mse_loss_black = nn.functional.mse_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        mse_loss_white = nn.functional.mse_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        focal_loss_black = focal_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        focal_loss_white = focal_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        total_loss = (alpha * (mse_loss_black + mse_loss_white) +\n",
    "                      beta * (focal_loss_black + focal_loss_white))\n",
    "\n",
    "    return total_loss, {\n",
    "        'mse_loss': (mse_loss_black + mse_loss_white).item() if not unified_cells else mse_loss.item(),\n",
    "        'focal_loss': (focal_loss_black + focal_loss_white).item() if not unified_cells else focal_loss_val.item(),\n",
    "        'l_push': 0.0,\n",
    "        'l_pull': 0.0,\n",
    "        'total_loss': total_loss.item()\n",
    "    }\n",
    "\n",
    "\n",
    "def combined_loss(outputs, targets, alpha=1.0, beta=0.5, gamma=0.3, delta=0.2, sigma=2, unified_cells=False):\n",
    "    if unified_cells:\n",
    "        heatmap_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_true = targets[0]\n",
    "\n",
    "        mse_loss_val = nn.functional.mse_loss(heatmap_pred, heatmap_true)\n",
    "        focal_loss_val = focal_loss(heatmap_pred, heatmap_true)\n",
    "    else:\n",
    "        heatmap_black_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_white_pred = outputs[:, 1, :, :].unsqueeze(1)\n",
    "\n",
    "        heatmap_black_true = targets[0]\n",
    "        heatmap_white_true = targets[1]\n",
    "\n",
    "        mse_loss_black = nn.functional.mse_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        mse_loss_white = nn.functional.mse_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        focal_loss_black = focal_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        focal_loss_white = focal_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        mse_loss_val = mse_loss_black + mse_loss_white\n",
    "        focal_loss_val = focal_loss_black + focal_loss_white\n",
    "\n",
    "    l_push, l_pull = contrast_loss_torch(outputs, targets, sigma, unified_cells)\n",
    "\n",
    "    total_loss = alpha * mse_loss_val + beta * focal_loss_val + gamma * l_push + delta * l_pull\n",
    "\n",
    "    return total_loss, {\n",
    "        'mse_loss': mse_loss_val.item(),\n",
    "        'focal_loss': focal_loss_val.item(),\n",
    "        'l_push': float(l_push.detach().cpu()),\n",
    "        'l_pull': float(l_pull.detach().cpu()),\n",
    "        'total_loss': float(total_loss.detach().cpu()),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluation_mse_loss(outputs, targets, unified_cells=False):\n",
    "    if unified_cells:\n",
    "        heatmap_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_true = targets[0]\n",
    "        return nn.functional.mse_loss(heatmap_pred, heatmap_true)\n",
    "    else:\n",
    "        heatmap_black_pred = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        heatmap_white_pred = outputs[:, 1, :, :].unsqueeze(1)\n",
    "\n",
    "        heatmap_black_true = targets[0]\n",
    "        heatmap_white_true = targets[1]\n",
    "\n",
    "        mse_loss_black = nn.functional.mse_loss(heatmap_black_pred, heatmap_black_true)\n",
    "        mse_loss_white = nn.functional.mse_loss(heatmap_white_pred, heatmap_white_true)\n",
    "\n",
    "        return mse_loss_black + mse_loss_white\n",
    "\n",
    "\n",
    "def safe_tensor_check(tensor, name=\"tensor\"):\n",
    "    if torch.any(~torch.isfinite(tensor)):\n",
    "        tensor = torch.nan_to_num(tensor, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_loss_function(loss_type, loss_weights, unified_cells=False):\n",
    "    if loss_type == 'mse':\n",
    "        return lambda outputs, targets: mse_loss_only(outputs, targets, unified_cells)\n",
    "    elif loss_type == 'mse_focal':\n",
    "        return lambda outputs, targets: mse_focal_loss(\n",
    "            outputs, targets,\n",
    "            alpha=loss_weights.get('alpha', 1.0),\n",
    "            beta=loss_weights.get('beta', 0.5),\n",
    "            unified_cells=unified_cells\n",
    "        )\n",
    "    elif loss_type == 'mse_focal_contrast':\n",
    "        return lambda outputs, targets: combined_loss(\n",
    "            outputs, targets,\n",
    "            alpha=loss_weights.get('alpha', 1.0),\n",
    "            beta=loss_weights.get('beta', 0.5),\n",
    "            gamma=loss_weights.get('gamma', 0.3),\n",
    "            delta=loss_weights.get('delta', 0.2),\n",
    "            sigma=loss_weights.get('sigma', 2.0),\n",
    "            unified_cells=unified_cells\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709fdccff3bfec4",
   "metadata": {},
   "source": [
    "Now let’s define our evaluation metrics and their visualizations to assess the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d5415ada08225a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.429335Z",
     "start_time": "2025-09-03T01:11:13.408809Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmap, threshold=0.5, min_distance=10):\n",
    "    if torch.is_tensor(heatmap):\n",
    "        heatmap = heatmap.cpu().numpy()\n",
    "\n",
    "    binary_map = heatmap > threshold\n",
    "\n",
    "    local_maxima = maximum_filter(heatmap, size=min_distance) == heatmap\n",
    "    local_maxima = local_maxima & binary_map\n",
    "\n",
    "    y_coords, x_coords = np.where(local_maxima)\n",
    "\n",
    "    keypoints = [(x, y) for x, y in zip(x_coords, y_coords)]\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def calculate_pck(pred_keypoints, true_keypoints, threshold=20):\n",
    "    if len(pred_keypoints) == 0 or len(true_keypoints) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    pred_array = np.array(pred_keypoints)\n",
    "    true_array = np.array(true_keypoints)\n",
    "\n",
    "    distances = cdist(pred_array, true_array)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    correct_keypoints = np.sum(min_distances < threshold)\n",
    "    pck = correct_keypoints / len(pred_keypoints)\n",
    "\n",
    "    return pck\n",
    "\n",
    "\n",
    "def calculate_ap(pred_heatmap, true_heatmap, threshold=0.5):\n",
    "    if torch.is_tensor(pred_heatmap):\n",
    "        pred_heatmap = pred_heatmap.cpu().numpy()\n",
    "    if torch.is_tensor(true_heatmap):\n",
    "        true_heatmap = true_heatmap.cpu().numpy()\n",
    "\n",
    "    pred_flat = pred_heatmap.flatten()\n",
    "    true_flat = (true_heatmap > threshold).astype(int).flatten()\n",
    "\n",
    "    try:\n",
    "        ap = average_precision_score(true_flat, pred_flat)\n",
    "    except:\n",
    "        ap = 0.0\n",
    "\n",
    "    return ap\n",
    "\n",
    "\n",
    "def create_output_directory(dataset_name):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f\"training_results_{dataset_name}_{timestamp}\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"predictions\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"plots\"), exist_ok=True)\n",
    "\n",
    "    return output_dir\n",
    "\n",
    "\n",
    "def create_custom_colormap():\n",
    "    red_cmap = plt.cm.Reds\n",
    "    blue_cmap = plt.cm.Blues\n",
    "    return red_cmap, blue_cmap\n",
    "\n",
    "\n",
    "def visualize_predictions_improved(model, data_loader, epoch, output_dir, num_samples=4, unified_cells=False):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    images, targets = next(iter(data_loader))\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    images_np = images.cpu().numpy()\n",
    "    targets_first_np = targets[0].cpu().numpy()\n",
    "    targets_second_np = targets[1].cpu().numpy()\n",
    "\n",
    "    if unified_cells:\n",
    "        outputs_unified_np = outputs[:, 0, :, :].cpu().numpy()\n",
    "    else:\n",
    "        outputs_black_np = outputs[:, 0, :, :].cpu().numpy()\n",
    "        outputs_white_np = outputs[:, 1, :, :].cpu().numpy()\n",
    "\n",
    "    red_cmap, blue_cmap = create_custom_colormap()\n",
    "\n",
    "    for i in range(min(num_samples, images.shape[0])):\n",
    "        img = np.transpose(images_np[i], (1, 2, 0))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title('DataMatrix Image', fontsize=14, fontweight='bold')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        if unified_cells:\n",
    "            gt_combined = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            gt_combined[:, :, 1] = targets_first_np[i, 0]\n",
    "\n",
    "            axes[1].imshow(gt_combined, vmin=0, vmax=1)\n",
    "            axes[1].set_title('Ground Truth Heatmap\\n(Green: All Cells)', fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            pred_combined = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            pred_combined[:, :, 1] = outputs_unified_np[i]\n",
    "\n",
    "            axes[2].imshow(pred_combined, vmin=0, vmax=1)\n",
    "            axes[2].set_title('Predicted Heatmap\\n(Green: All Cells)', fontsize=14, fontweight='bold')\n",
    "            axes[2].axis('off')\n",
    "        else:\n",
    "            gt_combined = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            gt_combined[:, :, 0] = targets_first_np[i, 0]\n",
    "            gt_combined[:, :, 2] = targets_second_np[i, 0]\n",
    "\n",
    "            axes[1].imshow(gt_combined, vmin=0, vmax=1)\n",
    "            axes[1].set_title('Ground Truth Heatmap\\n(Red: Black, Blue: White)', fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            pred_combined = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            pred_combined[:, :, 0] = outputs_black_np[i]\n",
    "            pred_combined[:, :, 2] = outputs_white_np[i]\n",
    "\n",
    "            axes[2].imshow(pred_combined, vmin=0, vmax=1)\n",
    "            axes[2].set_title('Predicted Heatmap\\n(Red: Black, Blue: White)', fontsize=14, fontweight='bold')\n",
    "            axes[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"epoch_{epoch:03d}_sample_{i:02d}.png\"\n",
    "        filepath = os.path.join(output_dir, \"predictions\", filename)\n",
    "        plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def visualize_augmented_samples(dataset, num_samples=4, save_path=None):\n",
    "    original_augment = dataset.augment\n",
    "    original_prob = dataset.augment_prob\n",
    "    dataset.set_augmentation(True, 1.0)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(5 * num_samples, 10))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        dataset.set_augmentation(False, 0.0)\n",
    "        img_orig, (heatmap_first_orig, heatmap_second_orig) = dataset[i]\n",
    "\n",
    "        dataset.set_augmentation(True, 1.0)\n",
    "        img_aug, (heatmap_first_aug, heatmap_second_aug) = dataset[i]\n",
    "\n",
    "        img_orig_np = img_orig.permute(1, 2, 0).numpy()\n",
    "        img_aug_np = img_aug.permute(1, 2, 0).numpy()\n",
    "\n",
    "        overlay_orig = img_orig_np.copy()\n",
    "        overlay_aug = img_aug_np.copy()\n",
    "\n",
    "        if dataset.unified_cells:\n",
    "            overlay_orig[:, :, 1] = np.maximum(overlay_orig[:, :, 1], heatmap_first_orig[0].numpy() * 0.8)\n",
    "            overlay_aug[:, :, 1] = np.maximum(overlay_aug[:, :, 1], heatmap_first_aug[0].numpy() * 0.8)\n",
    "        else:\n",
    "            overlay_orig[:, :, 0] = np.maximum(overlay_orig[:, :, 0], heatmap_first_orig[0].numpy() * 0.8)\n",
    "            overlay_orig[:, :, 2] = np.maximum(overlay_orig[:, :, 2], heatmap_second_orig[0].numpy() * 0.8)\n",
    "            overlay_aug[:, :, 0] = np.maximum(overlay_aug[:, :, 0], heatmap_first_aug[0].numpy() * 0.8)\n",
    "            overlay_aug[:, :, 2] = np.maximum(overlay_aug[:, :, 2], heatmap_second_aug[0].numpy() * 0.8)\n",
    "\n",
    "        axes[0, i].imshow(overlay_orig)\n",
    "        axes[0, i].set_title(f'Original Sample {i + 1}', fontweight='bold')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(overlay_aug)\n",
    "        axes[1, i].set_title(f'Augmented Sample {i + 1}', fontweight='bold')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    dataset.set_augmentation(original_augment, original_prob)\n",
    "\n",
    "\n",
    "def plot_training_metrics(train_losses, val_losses, ap_scores, pck_black_scores, pck_white_scores,\n",
    "                          contrast_push_losses, contrast_pull_losses, output_dir, loss_type, unified_cells=False):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    if loss_type == 'mse_focal_contrast':\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "        subplot_config = [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        subplot_config = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "    ax = axes[subplot_config[0]]\n",
    "    ax.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=3, marker='o', markersize=4)\n",
    "    ax.set_title(f'Training Loss ({loss_type.upper()})', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axes[subplot_config[1]]\n",
    "    ax.plot(epochs, val_losses, 'r-', label='Validation Loss (MSE)', linewidth=3, marker='s', markersize=4)\n",
    "    ax.set_title('Validation Loss (MSE - Standardized)', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axes[subplot_config[2]]\n",
    "    ax.plot(epochs, ap_scores, 'g-', label='Average Precision', linewidth=3, marker='^', markersize=4)\n",
    "    ax.set_title('Average Precision Score', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('AP Score', fontsize=12)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if unified_cells:\n",
    "        ax = axes[subplot_config[3]]\n",
    "        ax.plot(epochs, pck_black_scores, 'purple', label='PCK All Cells', linewidth=3, marker='D', markersize=4)\n",
    "        ax.set_title('PCK Score - All Cells', fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Epoch', fontsize=12)\n",
    "        ax.set_ylabel('PCK Score', fontsize=12)\n",
    "        ax.legend(fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax = axes[subplot_config[3]]\n",
    "        ax.plot(epochs, pck_black_scores, 'darkred', label='PCK Black Cells', linewidth=3, marker='v', markersize=4)\n",
    "        ax.plot(epochs, pck_white_scores, 'darkblue', label='PCK White Cells', linewidth=3, marker='*', markersize=6)\n",
    "        ax.set_title('PCK Scores - Black vs White Cells', fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Epoch', fontsize=12)\n",
    "        ax.set_ylabel('PCK Score', fontsize=12)\n",
    "        ax.legend(fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if loss_type == 'mse_focal_contrast':\n",
    "        ax = axes[subplot_config[4]]\n",
    "        ax.plot(epochs, contrast_push_losses, 'orange', label='L_push', linewidth=3, marker='h', markersize=4)\n",
    "        ax.set_title('Contrast Loss - L_push Loss', fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Epoch', fontsize=12)\n",
    "        ax.set_ylabel('L_push Loss', fontsize=12)\n",
    "        ax.legend(fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[subplot_config[5]]\n",
    "        ax.plot(epochs, contrast_pull_losses, 'purple', label='L_pull', linewidth=3, marker='p', markersize=4)\n",
    "        ax.set_title('Contrast Loss - L_pull Loss', fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Epoch', fontsize=12)\n",
    "        ax.set_ylabel('L_pull Loss', fontsize=12)\n",
    "        ax.legend(fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    mode_suffix = \"_unified\" if unified_cells else \"_separated\"\n",
    "    plt.savefig(os.path.join(output_dir, \"plots\", f\"training_metrics_{loss_type}{mode_suffix}.png\"),\n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label=f'Train Loss ({loss_type.upper()})',\n",
    "             linewidth=3, marker='o', markersize=6)\n",
    "    plt.title('Training Loss Evolution', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss (MSE)',\n",
    "             linewidth=3, marker='s', markersize=6)\n",
    "    plt.title('Validation Loss Evolution', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"plots\", f\"train_vs_val_losses{mode_suffix}.png\"),\n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    if loss_type == 'mse_focal_contrast':\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(epochs, contrast_push_losses, 'orange', label='L_push', linewidth=3,\n",
    "                 marker='o', markersize=5, alpha=0.8)\n",
    "        plt.plot(epochs, contrast_pull_losses, 'purple', label='L_pull', linewidth=3,\n",
    "                 marker='s', markersize=5, alpha=0.8)\n",
    "        plt.title('Contrast Losses Comparison', fontsize=18, fontweight='bold')\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss Value', fontsize=14)\n",
    "        plt.legend(fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"plots\", f\"contrast_losses_comparison{mode_suffix}.png\"),\n",
    "                    dpi=150, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a453d2c71033a3",
   "metadata": {},
   "source": [
    "Let’s implement a mechanism to save model weights during training (checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a787b4f413b5ce1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.480159Z",
     "start_time": "2025-09-03T01:11:13.477541Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, epoch, optimizer, scheduler, output_dir, is_best=False):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }\n",
    "\n",
    "    filename = f'model_epoch_{epoch:03d}.pth'\n",
    "    if is_best:\n",
    "        filename = f'best_model_epoch_{epoch:03d}.pth'\n",
    "\n",
    "    filepath = os.path.join(output_dir, \"models\", filename)\n",
    "    torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c2bdc7c33eb36",
   "metadata": {},
   "source": [
    "Let’s implement functions to visualize system resource usage during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3154eba94e1918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.531962Z",
     "start_time": "2025-09-03T01:11:13.528856Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 3)\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
    "\n",
    "\n",
    "def monitor_gpu_power(log_interval, stop_event, power_data):\n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits'],\n",
    "                stdout=subprocess.PIPE, text=True, timeout=5\n",
    "            )\n",
    "            power = float(result.stdout.strip().split('\\n')[0])\n",
    "            power_data.append((time.time(), power))\n",
    "        except (ValueError, subprocess.TimeoutExpired):\n",
    "            pass\n",
    "        time.sleep(log_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222913f60d2a3f1",
   "metadata": {},
   "source": [
    "Finally, let’s implement our model’s training function—covering the training loop, visualization of evaluation metrics, choosing the model’s hyperparameters and an estimate of the training’s environmental impact (carbon footprint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc20787a5d11b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T01:11:13.604601Z",
     "start_time": "2025-09-03T01:11:13.580257Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_configurable(model, train_loader, val_loader, optimizer, scheduler, num_epochs, output_dir,\n",
    "                             dataset_name, loss_type, loss_weights, use_augmentation, backbone, unified_cells=False):\n",
    "    device = next(model.parameters()).device\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    ap_scores = []\n",
    "    pck_black_scores = []\n",
    "    pck_white_scores = []\n",
    "    contrast_push_losses = []\n",
    "    contrast_pull_losses = []\n",
    "\n",
    "    train_loss_fn = get_loss_function(loss_type, loss_weights, unified_cells)\n",
    "\n",
    "    power_data = []\n",
    "    stop_event = threading.Event()\n",
    "    monitor_thread = threading.Thread(target=monitor_gpu_power, args=(5, stop_event, power_data))\n",
    "    monitor_thread.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\" Starting configurable training - Dataset: {dataset_name}\")\n",
    "    print(f\"️  Backbone: {backbone.upper()}\")\n",
    "    print(f\" Training loss: {loss_type.upper()}\")\n",
    "    print(f\" Evaluation loss: MSE (standardized)\")\n",
    "    print(f\" Data augmentation: {'ENABLED' if use_augmentation else 'DISABLED'}\")\n",
    "    print(f\" Cell detection mode: {'UNIFIED (all cells)' if unified_cells else 'SEPARATED (black/white)'}\")\n",
    "    print(f\"️  Loss weights: {loss_weights}\")\n",
    "    print(f\" Results saved to: {output_dir}\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        print_memory_usage()\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        epoch_push_losses = []\n",
    "        epoch_pull_losses = []\n",
    "\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            heatmap_first, heatmap_second = targets\n",
    "            heatmap_first = heatmap_first.to(device)\n",
    "            heatmap_second = heatmap_second.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss, loss_components = train_loss_fn(outputs, (heatmap_first, heatmap_second))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            epoch_push_losses.append(loss_components['l_push'])\n",
    "            epoch_pull_losses.append(loss_components['l_pull'])\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        epoch_ap_scores = []\n",
    "        epoch_pck_black_scores = []\n",
    "        epoch_pck_white_scores = []\n",
    "        val_push_losses = []\n",
    "        val_pull_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx, (images, targets) in enumerate(val_loader):\n",
    "                images = images.to(device)\n",
    "                heatmap_first, heatmap_second = targets\n",
    "                heatmap_first = heatmap_first.to(device)\n",
    "                heatmap_second = heatmap_second.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                mse_loss = evaluation_mse_loss(outputs, (heatmap_first, heatmap_second), unified_cells)\n",
    "                val_loss += mse_loss.item() * images.size(0)\n",
    "\n",
    "                if loss_type == 'mse_focal_contrast':\n",
    "                    _, contrast_components = combined_loss(\n",
    "                        outputs, (heatmap_first, heatmap_second),\n",
    "                        alpha=loss_weights.get('alpha', 1.0),\n",
    "                        beta=loss_weights.get('beta', 0.5),\n",
    "                        gamma=loss_weights.get('gamma', 0.3),\n",
    "                        delta=loss_weights.get('delta', 0.2),\n",
    "                        sigma=loss_weights.get('sigma', 2.0),\n",
    "                        unified_cells=unified_cells\n",
    "                    )\n",
    "                    val_push_losses.append(contrast_components['l_push'])\n",
    "                    val_pull_losses.append(contrast_components['l_pull'])\n",
    "                else:\n",
    "                    val_push_losses.append(0.0)\n",
    "                    val_pull_losses.append(0.0)\n",
    "\n",
    "                for i in range(images.size(0)):\n",
    "                    if unified_cells:\n",
    "\n",
    "                        ap_unified = calculate_ap(outputs[i, 0], heatmap_first[i, 0])\n",
    "                        epoch_ap_scores.append(ap_unified)\n",
    "\n",
    "                        pred_unified_kpts = extract_keypoints_from_heatmap(outputs[i, 0])\n",
    "                        true_unified_kpts = extract_keypoints_from_heatmap(heatmap_first[i, 0])\n",
    "                        pck_unified = calculate_pck(pred_unified_kpts, true_unified_kpts)\n",
    "                        epoch_pck_black_scores.append(pck_unified)  \n",
    "                        epoch_pck_white_scores.append(pck_unified) \n",
    "                    else:\n",
    "                        ap_black = calculate_ap(outputs[i, 0], heatmap_first[i, 0])\n",
    "                        ap_white = calculate_ap(outputs[i, 1], heatmap_second[i, 0])\n",
    "                        epoch_ap_scores.append((ap_black + ap_white) / 2)\n",
    "\n",
    "                        pred_black_kpts = extract_keypoints_from_heatmap(outputs[i, 0])\n",
    "                        true_black_kpts = extract_keypoints_from_heatmap(heatmap_first[i, 0])\n",
    "                        pck_black = calculate_pck(pred_black_kpts, true_black_kpts)\n",
    "                        epoch_pck_black_scores.append(pck_black)\n",
    "\n",
    "                        pred_white_kpts = extract_keypoints_from_heatmap(outputs[i, 1])\n",
    "                        true_white_kpts = extract_keypoints_from_heatmap(heatmap_second[i, 0])\n",
    "                        pck_white = calculate_pck(pred_white_kpts, true_white_kpts)\n",
    "                        epoch_pck_white_scores.append(pck_white)\n",
    "\n",
    "                if val_batch_idx % 10 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        avg_ap = np.mean(epoch_ap_scores) if epoch_ap_scores else 0.0\n",
    "        avg_pck_black = np.mean(epoch_pck_black_scores) if epoch_pck_black_scores else 0.0\n",
    "        avg_pck_white = np.mean(epoch_pck_white_scores) if epoch_pck_white_scores else 0.0\n",
    "        avg_push_loss = np.mean(epoch_push_losses + val_push_losses)\n",
    "        avg_pull_loss = np.mean(epoch_pull_losses + val_pull_losses)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        ap_scores.append(avg_ap)\n",
    "        pck_black_scores.append(avg_pck_black)\n",
    "        pck_white_scores.append(avg_pck_white)\n",
    "        contrast_push_losses.append(avg_push_loss)\n",
    "        contrast_pull_losses.append(avg_pull_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            save_model_checkpoint(model, epoch, optimizer, scheduler, output_dir, is_best=True)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_model_checkpoint(model, epoch, optimizer, scheduler, output_dir)\n",
    "\n",
    "        loss_display = f'Train({loss_type.upper()}): {train_loss:.4f} | Val(MSE): {val_loss:.4f}'\n",
    "\n",
    "        if unified_cells:\n",
    "            metrics_display = f'AP: {avg_ap:.4f} | PCK_All: {avg_pck_black:.4f}'\n",
    "        else:\n",
    "            metrics_display = f'AP: {avg_ap:.4f} | PCK_B: {avg_pck_black:.4f} | PCK_W: {avg_pck_white:.4f}'\n",
    "\n",
    "        if loss_type == 'mse_focal_contrast':\n",
    "            contrast_display = f' | L_push: {avg_push_loss:.4f} | L_pull: {avg_pull_loss:.4f}'\n",
    "        else:\n",
    "            contrast_display = ''\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1:3d}/{num_epochs} | {loss_display} | {metrics_display}{contrast_display} | LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            visualize_predictions_improved(model, val_loader, epoch + 1, output_dir, unified_cells=unified_cells)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plot_training_metrics(train_losses, val_losses, ap_scores,\n",
    "                                  pck_black_scores, pck_white_scores,\n",
    "                                  contrast_push_losses, contrast_pull_losses, output_dir, loss_type, unified_cells)\n",
    "\n",
    "    stop_event.set()\n",
    "    monitor_thread.join()\n",
    "    end_time = time.time()\n",
    "\n",
    "    visualize_predictions_improved(model, val_loader, num_epochs, output_dir, num_samples=8,\n",
    "                                   unified_cells=unified_cells)\n",
    "    plot_training_metrics(train_losses, val_losses, ap_scores,\n",
    "                          pck_black_scores, pck_white_scores,\n",
    "                          contrast_push_losses, contrast_pull_losses, output_dir, loss_type, unified_cells)\n",
    "\n",
    "    duration_hours = (end_time - start_time) / 3600\n",
    "    if power_data:\n",
    "        df_power = pd.DataFrame(power_data, columns=['timestamp', 'power_watts'])\n",
    "        mean_power = df_power['power_watts'].mean()\n",
    "        energy_consumed_kwh = (mean_power * duration_hours) / 1000\n",
    "        CO2_FACTOR_BELGIUM = 0.11  \n",
    "        carbon_impact_kg = energy_consumed_kwh * CO2_FACTOR_BELGIUM\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\" ENERGY REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\" Training duration: {duration_hours:.2f} h\")\n",
    "        print(f\" Average GPU power: {mean_power:.2f} W\")\n",
    "        print(f\" GPU energy consumed: {energy_consumed_kwh:.4f} kWh\")\n",
    "        print(f\" Estimated carbon footprint (Belgium): {carbon_impact_kg * 1000:.2f} g CO2\")\n",
    "\n",
    "        df_power.to_csv(os.path.join(output_dir, \"gpu_power_log.csv\"), index=False)\n",
    "\n",
    "    print(f\"\\n Best model: Epoch {best_epoch + 1} with validation loss (MSE) = {best_val_loss:.4f}\")\n",
    "    print(f\" Complete results available in: {output_dir}\")\n",
    "\n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'final_ap': ap_scores[-1] if ap_scores else 0,\n",
    "        'final_pck_black': pck_black_scores[-1] if pck_black_scores else 0,\n",
    "        'final_pck_white': pck_white_scores[-1] if pck_white_scores else 0,\n",
    "        'final_l_push': contrast_push_losses[-1] if contrast_push_losses else 0,\n",
    "        'final_l_pull': contrast_pull_losses[-1] if contrast_pull_losses else 0,\n",
    "        'training_time_hours': duration_hours,\n",
    "        'loss_type': loss_type,\n",
    "        'use_augmentation': use_augmentation,\n",
    "        'backbone': backbone,\n",
    "        'unified_cells': unified_cells\n",
    "    }\n",
    "\n",
    "\n",
    "def get_user_configuration():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"CONFIGURATION SETUP\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(\"\\n  SELECT BACKBONE ARCHITECTURE:\")\n",
    "    print(\"1. ResNet-18 \")\n",
    "    print(\"2. ResNet-34 \")\n",
    "    print(\"3. ResNet-50 \")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            backbone_choice = int(input(\"\\nEnter your choice (1-3): \"))\n",
    "            if backbone_choice in [1, 2, 3]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter 1, 2, or 3\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "\n",
    "    backbone_types = {1: 'resnet18', 2: 'resnet34', 3: 'resnet50'}\n",
    "    backbone = backbone_types[backbone_choice]\n",
    "\n",
    "    print(\"\\n SELECT CELL DETECTION MODE:\")\n",
    "    print(\"1. Separated mode - Distinguish black (v=2) and white (v=1) cells\")\n",
    "    print(\"2. Unified mode - Detect all cells (v=1 or v=2) without polarity distinction\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            cell_mode_choice = int(input(\"\\nEnter your choice (1-2): \"))\n",
    "            if cell_mode_choice in [1, 2]:\n",
    "                break\n",
    "            else:\n",
    "                print(\" Please enter 1 or 2\")\n",
    "        except ValueError:\n",
    "            print(\" Please enter a valid number\")\n",
    "\n",
    "    unified_cells = cell_mode_choice == 2\n",
    "\n",
    "    print(\"\\n SELECT LOSS FUNCTION:\")\n",
    "    print(\"1. MSE only\")\n",
    "    print(\"2. MSE + Focal Loss\")\n",
    "    print(\"3. MSE + Focal Loss + Contrast Loss\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            loss_choice = int(input(\"\\nEnter your choice (1-3): \"))\n",
    "            if loss_choice in [1, 2, 3]:\n",
    "                break\n",
    "            else:\n",
    "                print(\" Please enter 1, 2, or 3\")\n",
    "        except ValueError:\n",
    "            print(\" Please enter a valid number\")\n",
    "\n",
    "    loss_types = {1: 'mse', 2: 'mse_focal', 3: 'mse_focal_contrast'}\n",
    "    loss_type = loss_types[loss_choice]\n",
    "\n",
    "    print(\"\\n ENABLE DATA AUGMENTATION:\")\n",
    "    print(\"1. Yes - Enable online data augmentation\")\n",
    "    print(\"2. No - Disable data augmentation\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            aug_choice = int(input(\"\\nEnter your choice (1-2): \"))\n",
    "            if aug_choice in [1, 2]:\n",
    "                break\n",
    "            else:\n",
    "                print(\" Please enter 1 or 2\")\n",
    "        except ValueError:\n",
    "            print(\" Please enter a valid number\")\n",
    "\n",
    "    use_augmentation = aug_choice == 1\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" CONFIGURATION SELECTED:\")\n",
    "    print(f\"️     Backbone: {backbone.upper()}\")\n",
    "    print(f\"     Cell mode: {'UNIFIED (all cells)' if unified_cells else 'SEPARATED (black/white)'}\")\n",
    "    print(f\"     Loss function: {loss_type.upper()}\")\n",
    "    print(f\"     Data augmentation: {'ENABLED' if use_augmentation else 'DISABLED'}\")\n",
    "    print(f\"     Evaluation: Always MSE (for fair comparison)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    return backbone, loss_type, use_augmentation, unified_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac242216599eda",
   "metadata": {},
   "source": [
    "Time to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0eea2913f2cc9",
   "metadata": {},
   "source": [
    " Please enter your configuration in CONFIG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc3cd5f5491bf8",
   "metadata": {},
   "source": [
    "After running the cell, you’ll need to choose the dataset, the backbone, the training loss function, and whether to apply data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7180c66b1b294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:57:19.656652Z",
     "start_time": "2025-09-03T01:11:13.629484Z"
    }
   },
   "outputs": [],
   "source": [
    "backbone, loss_type, use_augmentation, unified_cells = get_user_configuration()\n",
    "\n",
    "\n",
    "mode_suffix = \"_unified\" if unified_cells else \"_separated\"\n",
    "CONFIG = {\n",
    "    'dataset_name': f'DataMatrix_{backbone}_{loss_type}{\"_aug\" if use_augmentation else \"_no_aug\"}{mode_suffix}',\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 80,\n",
    "    'sigma': 2,\n",
    "    'weight_decay': 1e-4,\n",
    "    'target_size': (512, 512),\n",
    "\n",
    "    'train_json':,\n",
    "    'train_img_dir': ,\n",
    "    'val_json': ,\n",
    "    'val_img_dir': ,\n",
    "\n",
    "    'backbone': backbone,\n",
    "    'loss_type': loss_type,\n",
    "    'use_augmentation': use_augmentation,\n",
    "    'unified_cells': unified_cells,\n",
    "\n",
    "    'augmentation': {\n",
    "        'train_prob': 0.80 if use_augmentation else 0.0,\n",
    "        'val_prob': 0.0, \n",
    "    },\n",
    "\n",
    "    'loss_weights': {\n",
    "        'alpha': 1.0,  # MSE loss weight\n",
    "        'beta': 0.5,  # Focal loss weight\n",
    "        'gamma': 0.1,  # L_push loss weight\n",
    "        'delta': 0.4,  # L_pull loss weight\n",
    "        'sigma': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "output_dir = create_output_directory(CONFIG['dataset_name'])\n",
    "\n",
    "with open(os.path.join(output_dir, 'config.json'), 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "\n",
    "train_img_list = os.listdir(CONFIG['train_img_dir'])\n",
    "train_img_list = [f for f in train_img_list if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "val_img_list = os.listdir(CONFIG['val_img_dir'])\n",
    "val_img_list = [f for f in val_img_list if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "train_dataset = KeypointDatasetAugmented(\n",
    "    coco_json=CONFIG['train_json'],\n",
    "    img_dir=CONFIG['train_img_dir'],\n",
    "    img_list=train_img_list,\n",
    "    sigma=CONFIG['sigma'],  \n",
    "    target_size=CONFIG['target_size'],\n",
    "    augment=CONFIG['use_augmentation'],\n",
    "    augment_prob=CONFIG['augmentation']['train_prob'],\n",
    "    unified_cells=CONFIG['unified_cells']\n",
    ")\n",
    "\n",
    "val_dataset = KeypointDatasetAugmented(\n",
    "    coco_json=CONFIG['val_json'],\n",
    "    img_dir=CONFIG['val_img_dir'],\n",
    "    img_list=val_img_list,\n",
    "    sigma=CONFIG['sigma'],  \n",
    "    target_size=CONFIG['target_size'],\n",
    "    augment=False, \n",
    "    augment_prob=0.0,\n",
    "    unified_cells=CONFIG['unified_cells']\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = KeypointDetector(backbone=CONFIG['backbone'], pretrained=True, unified_cells=CONFIG['unified_cells'])\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.7,\n",
    "    patience=8,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "if CONFIG['use_augmentation']:\n",
    "    viz_path = os.path.join(output_dir, \"augmentation_preview.png\")\n",
    "    visualize_augmented_samples(train_dataset, num_samples=4, save_path=viz_path)\n",
    "\n",
    "results = train_model_configurable(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=CONFIG['epochs'],\n",
    "    output_dir=output_dir,\n",
    "    dataset_name=CONFIG['dataset_name'],\n",
    "    loss_type=CONFIG['loss_type'],\n",
    "    loss_weights=CONFIG['loss_weights'],\n",
    "    use_augmentation=CONFIG['use_augmentation'],\n",
    "    backbone=CONFIG['backbone'],\n",
    "    unified_cells=CONFIG['unified_cells']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3297ea8136727f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
