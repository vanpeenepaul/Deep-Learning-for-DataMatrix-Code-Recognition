{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87a86357723027f",
   "metadata": {},
   "source": [
    "This script aims to visualize all results obtained from other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from scipy.ndimage import map_coordinates\n",
    "import math\n",
    "import random\n",
    "import albumentations as A\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060d9f9e07c7f0b",
   "metadata": {},
   "source": [
    "Let's start by implementing the key functions from other notebooks. You can keep this cell collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99b56ae087e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, coco_json, img_dir, img_list=None, sigma=2, target_size=(512, 512),\n",
    "                 augment=False, augment_prob=0.8, unified_cells=False):\n",
    "\n",
    "        with open(coco_json, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "\n",
    "        self._clean_invalid_keypoints()\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.sigma = sigma\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.augment_prob = augment_prob\n",
    "        self.unified_cells = unified_cells\n",
    "\n",
    "        self.id_list = {ann['id'] for ann in self.coco_data['annotations']}\n",
    "        self.id_to_image_id = {ann['id']: ann['image_id'] for ann in self.coco_data['annotations']}\n",
    "        self.img_id_to_file = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
    "        self.id_to_keypoints = {ann['id']: ann['keypoints'] for ann in self.coco_data['annotations']}\n",
    "\n",
    "        self.img_to_anns = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.img_to_anns:\n",
    "                self.img_to_anns[img_id] = []\n",
    "            self.img_to_anns[img_id].append(ann)\n",
    "\n",
    "        if img_list:\n",
    "            self.img_ids = [\n",
    "                img_id for img_id in self.img_id_to_file\n",
    "                if self.img_id_to_file[img_id] in img_list and img_id in self.img_to_anns\n",
    "            ]\n",
    "        else:\n",
    "            self.img_ids = list(self.img_to_anns.keys())\n",
    "\n",
    "        if self.augment:\n",
    "            self.geometric_transform = A.Compose([\n",
    "                A.Rotate(limit=15, p=0.85, border_mode=cv2.BORDER_REFLECT),\n",
    "                A.HorizontalFlip(p=0.15),\n",
    "                A.VerticalFlip(p=0),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=15,\n",
    "                    border_mode=cv2.BORDER_REFLECT,\n",
    "                    p=0\n",
    "                ),\n",
    "            ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=True))\n",
    "\n",
    "            self.photometric_transform = A.Compose([\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.3,\n",
    "                    contrast_limit=0.2,\n",
    "                    p=0.7\n",
    "                ),\n",
    "                A.ColorJitter(\n",
    "                    brightness=0.2,\n",
    "                    contrast=0.2,\n",
    "                    saturation=0.2,\n",
    "                    hue=0.1,\n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=20,\n",
    "                    sat_shift_limit=30,\n",
    "                    val_shift_limit=20,\n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
    "                ], p=0.4),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=3, p=0.3),\n",
    "                    A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "                ], p=0.3),\n",
    "            ])\n",
    "        else:\n",
    "            self.geometric_transform = None\n",
    "            self.photometric_transform = None\n",
    "\n",
    "    def _clean_invalid_keypoints(self):\n",
    "        \n",
    "        cleaned_annotations = []\n",
    "        total_keypoints = 0\n",
    "        invalid_keypoints = 0\n",
    "\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            kpts = ann['keypoints']\n",
    "            cleaned_kpts = []\n",
    "\n",
    "            for i in range(0, len(kpts), 3):\n",
    "                x, y, v = kpts[i:i + 3]\n",
    "                total_keypoints += 1\n",
    "\n",
    "               \n",
    "                if np.isfinite(x) and np.isfinite(y) and not (np.isnan(x) or np.isnan(y)):\n",
    "                    cleaned_kpts.extend([float(x), float(y), int(v)])\n",
    "                else:\n",
    "                   \n",
    "                    cleaned_kpts.extend([0.0, 0.0, 0])\n",
    "                    invalid_keypoints += 1\n",
    "\n",
    "            ann['keypoints'] = cleaned_kpts\n",
    "            cleaned_annotations.append(ann)\n",
    "\n",
    "        self.coco_data['annotations'] = cleaned_annotations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def _extract_keypoints(self, annotations, original_width, original_height):\n",
    "       \n",
    "        keypoints = []\n",
    "        keypoint_info = []\n",
    "        invalid_count = 0\n",
    "\n",
    "        for ann in annotations:\n",
    "            kpts = ann['keypoints']\n",
    "            for i in range(0, len(kpts), 3):\n",
    "                x, y, v = kpts[i:i + 3]\n",
    "\n",
    "                if not (np.isfinite(x) and np.isfinite(y)) or np.isnan(x) or np.isnan(y):\n",
    "                    invalid_count += 1\n",
    "                    continue  \n",
    "\n",
    "                if v > 0:  \n",
    "                    \n",
    "                    if 0 <= x < original_width and 0 <= y < original_height:\n",
    "                        keypoints.append((float(x), float(y)))\n",
    "\n",
    "                        if self.unified_cells:\n",
    "                            visibility = 1\n",
    "                        else:\n",
    "                            visibility = v\n",
    "\n",
    "                        keypoint_info.append({\n",
    "                            'visibility': visibility,\n",
    "                            'label': 1 if self.unified_cells else v\n",
    "                        })\n",
    "                    else:\n",
    "                        \n",
    "                        invalid_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "        return keypoints, keypoint_info\n",
    "\n",
    "    def _apply_geometric_augmentation(self, image, keypoints):\n",
    "       \n",
    "        try:\n",
    "            if keypoints:\n",
    "                \n",
    "                valid_keypoints = []\n",
    "                for kp in keypoints:\n",
    "                    if len(kp) >= 2 and np.isfinite(kp[0]) and np.isfinite(kp[1]):\n",
    "                        valid_keypoints.append(kp)\n",
    "\n",
    "                if valid_keypoints:\n",
    "                    transformed = self.geometric_transform(image=image, keypoints=valid_keypoints)\n",
    "                    return transformed['image'], transformed['keypoints']\n",
    "                else:\n",
    "                   \n",
    "                    transformed = self.geometric_transform(image=image, keypoints=[])\n",
    "                    return transformed['image'], []\n",
    "            else:\n",
    "                transformed = self.geometric_transform(image=image, keypoints=[])\n",
    "                return transformed['image'], []\n",
    "        except Exception as e:\n",
    "            return image, keypoints\n",
    "\n",
    "    def _apply_photometric_augmentation(self, image):\n",
    "        try:\n",
    "            transformed = self.photometric_transform(image=image)\n",
    "            return transformed['image']\n",
    "        except Exception as e:\n",
    "            return image\n",
    "\n",
    "    def _create_heatmaps_from_keypoints(self, keypoints, keypoint_info, width, height):\n",
    "        if self.unified_cells:\n",
    "            heatmap_unified = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "            for (x, y), info in zip(keypoints, keypoint_info):\n",
    "               \n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    self._add_gaussian(heatmap_unified, x, y, self.sigma)\n",
    "\n",
    "            return heatmap_unified, np.zeros((height, width), dtype=np.float32)\n",
    "        else:\n",
    "            heatmap_black = np.zeros((height, width), dtype=np.float32)\n",
    "            heatmap_white = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "            for (x, y), info in zip(keypoints, keypoint_info):\n",
    "                \n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    if info['visibility'] == 2: \n",
    "                        self._add_gaussian(heatmap_black, x, y, self.sigma)\n",
    "                    elif info['visibility'] == 1:  \n",
    "                        self._add_gaussian(heatmap_white, x, y, self.sigma)\n",
    "\n",
    "            return heatmap_black, heatmap_white\n",
    "\n",
    "    def _add_gaussian(self, heatmap, x, y, sigma):\n",
    "        \n",
    "        height, width = heatmap.shape\n",
    "\n",
    "        \n",
    "        if not (np.isfinite(x) and np.isfinite(y)) or np.isnan(x) or np.isnan(y):\n",
    "            return \n",
    "\n",
    "        \n",
    "        try:\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            x, y = int(round(x)), int(round(y))\n",
    "        except (ValueError, OverflowError):\n",
    "            return  \n",
    "\n",
    "        \n",
    "        x = max(0, min(x, width - 1))\n",
    "        y = max(0, min(y, height - 1))\n",
    "\n",
    "        \n",
    "        size = 6 * sigma + 1\n",
    "        radius = int(size // 2)\n",
    "\n",
    "       \n",
    "        x0 = int(max(0, x - radius))\n",
    "        y0 = int(max(0, y - radius))\n",
    "        x1 = int(min(width, x + radius + 1))\n",
    "        y1 = int(min(height, y + radius + 1))\n",
    "\n",
    "        \n",
    "        xs = np.arange(x0, x1)\n",
    "        ys = np.arange(y0, y1)\n",
    "\n",
    "        if len(xs) == 0 or len(ys) == 0:\n",
    "            return \n",
    "        xx, yy = np.meshgrid(xs, ys)\n",
    "\n",
    "       \n",
    "        gaussian = np.exp(-((xx - x) ** 2 + (yy - y) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "       \n",
    "        try:\n",
    "            heatmap[y0:y1, x0:x1] = np.maximum(heatmap[y0:y1, x0:x1], gaussian)\n",
    "        except (ValueError, IndexError):\n",
    "            pass  \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_file = self.img_id_to_file[img_id]\n",
    "        img_path = os.path.join(self.img_dir, img_file)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            original_width, original_height = image.size\n",
    "\n",
    "           \n",
    "            image = image.resize(self.target_size, Image.LANCZOS)\n",
    "            image = np.array(image)\n",
    "\n",
    "            height, width = self.target_size\n",
    "            annotations = self.img_to_anns[img_id]\n",
    "\n",
    "            \n",
    "            keypoints, keypoint_info = self._extract_keypoints(annotations, original_width, original_height)\n",
    "\n",
    "            \n",
    "            scale_x = width / original_width\n",
    "            scale_y = height / original_height\n",
    "\n",
    "            scaled_keypoints = []\n",
    "            for x, y in keypoints:\n",
    "                new_x = x * scale_x\n",
    "                new_y = y * scale_y\n",
    "                \n",
    "                if np.isfinite(new_x) and np.isfinite(new_y):\n",
    "                    scaled_keypoints.append((new_x, new_y))\n",
    "\n",
    "            \n",
    "            if self.augment and random.random() < self.augment_prob:\n",
    "                \n",
    "                image, scaled_keypoints = self._apply_geometric_augmentation(image, scaled_keypoints)\n",
    "\n",
    "                image = self._apply_photometric_augmentation(image)\n",
    "\n",
    "            \n",
    "            heatmap_first, heatmap_second = self._create_heatmaps_from_keypoints(\n",
    "                scaled_keypoints, keypoint_info[:len(scaled_keypoints)], width, height\n",
    "            )\n",
    "\n",
    "            \n",
    "            if not (np.isfinite(heatmap_first).all() and np.isfinite(heatmap_second).all()):\n",
    "                heatmap_first = np.nan_to_num(heatmap_first, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                heatmap_second = np.nan_to_num(heatmap_second, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "           \n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            heatmap_first = torch.from_numpy(heatmap_first).unsqueeze(0).float()\n",
    "            heatmap_second = torch.from_numpy(heatmap_second).unsqueeze(0).float()\n",
    "\n",
    "            return image, (heatmap_first, heatmap_second)\n",
    "\n",
    "        except Exception as e:\n",
    "            height, width = self.target_size\n",
    "            empty_image = torch.zeros(3, height, width, dtype=torch.float32)\n",
    "            empty_heatmap = torch.zeros(1, height, width, dtype=torch.float32)\n",
    "            return empty_image, (empty_heatmap, empty_heatmap)\n",
    "\n",
    "    def set_augmentation(self, enabled, prob=0.8):\n",
    "        self.augment = enabled\n",
    "        self.augment_prob = prob\n",
    "\n",
    "\n",
    "def separate_keypoints_by_visibility(kp):\n",
    "    \"\"\"Separate black and white points based on their visibility\"\"\"\n",
    "    x_black, y_black, x_white, y_white = [], [], [], []\n",
    "    for i in range(0, len(kp), 3):\n",
    "        if kp[i + 2] == 2:\n",
    "            x_black.append(kp[i])\n",
    "            y_black.append(kp[i + 1])\n",
    "        else:\n",
    "            x_white.append(kp[i])\n",
    "            y_white.append(kp[i + 1])\n",
    "    return x_black, y_black, x_white, y_white\n",
    "\n",
    "\n",
    "def apply_transformation(image_path, kp_v, kp_xy, transform):\n",
    "    \"\"\"Apply transformation to image and keypoints\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "\n",
    "    augmented = transform(image=image, keypoints=kp_xy)\n",
    "\n",
    "    transformed_kps = []\n",
    "    for i in range(len(kp_xy)):\n",
    "        x, y = augmented['keypoints'][i]\n",
    "        v = kp_v[i]\n",
    "        transformed_kps.extend([x, y, v])\n",
    "\n",
    "    return augmented['image'], transformed_kps\n",
    "\n",
    "\n",
    "def create_transformation_visualization(full_name, keypoints_v, keypoints_xy, transformations,\n",
    "                                        output_pdf_path, title_prefix=\"Transformation\", main_title=None):\n",
    "    \"\"\"Create visualization of transformations\"\"\"\n",
    "    n = len(transformations)\n",
    "    cols = 3\n",
    "    rows = n\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * 5, rows * 4.5))  \n",
    "\n",
    "    if main_tit\n",
    "        fig.suptitle(main_title, fontsize=16, fontweight='bold', y=0.96) \n",
    "\n",
    "    with PdfPages(output_pdf_path) as pdf:\n",
    "        for i, (name, transform) in enumerate(transformations.items()):\n",
    "            img_aug, kps_aug = apply_transformation(full_name, keypoints_v, keypoints_xy, transform)\n",
    "\n",
    "           \n",
    "            if img_aug.dtype != np.uint8:\n",
    "                if img_aug.max() <= 1.0:\n",
    "                    img_aug = (img_aug * 255).clip(0, 255).astype(np.uint8)\n",
    "                else:\n",
    "                    img_aug = img_aug.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "            x_black, y_black, x_white, y_white = separate_keypoints_by_visibility(kps_aug)\n",
    "\n",
    "            print(f\"{title_prefix} {i}: {name}\")\n",
    "\n",
    "            \n",
    "            plt.subplot(rows, cols, i * cols + 1)\n",
    "            image_orig = Image.open(full_name).convert('RGB')\n",
    "            plt.imshow(image_orig)\n",
    "            plt.title(\"Original Image\", fontsize=12, pad=10)\n",
    "            plt.axis('off')\n",
    "\n",
    "            \n",
    "            plt.subplot(rows, cols, i * cols + 2)\n",
    "            plt.imshow(img_aug)\n",
    "            plt.title(f\"{name}\", fontsize=12, pad=10)\n",
    "            plt.axis('off')\n",
    "\n",
    "            \n",
    "            plt.subplot(rows, cols, i * cols + 3)\n",
    "            plt.imshow(img_aug)\n",
    "            plt.scatter(x_black, y_black, c='r', label='black', s=6)  # Reduced size from 15 to 6\n",
    "            plt.scatter(x_white, y_white, c='b', label='white', s=6)  # Reduced size from 15 to 6\n",
    "            plt.title(\"Image and Annotations Overlay\", fontsize=12, pad=10)\n",
    "            plt.axis('off')\n",
    "            plt.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "        plt.tight_layout(pad=2.0)\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def apply_curvature_transform(image, curvature_factor=0.3):\n",
    "    \"\"\"Apply curvature transformation to simulate datamatrix bending\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    y_dest, x_dest = np.mgrid[0:height, 0:width]\n",
    "    x_source = x_dest - curvature_factor * np.sin(2 * np.pi * y_dest / height) * width\n",
    "    y_source = y_dest.astype(float)\n",
    "\n",
    "    result = np.zeros_like(image)\n",
    "    for c in range(image.shape[2]):\n",
    "        result[..., c] = map_coordinates(image[..., c], [y_source, x_source], order=1, mode='constant', cval=255)\n",
    "\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "\n",
    "def deform_keypoints_curvature(keypoints, height, width, curvature_factor=0.3):\n",
    "    \"\"\"Apply curvature deformation to keypoints\"\"\"\n",
    "    new_keypoints = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i], keypoints[i + 1], keypoints[i + 2]\n",
    "        if v > 0:\n",
    "            delta_x = curvature_factor * np.sin(2 * np.pi * y / height) * width\n",
    "            x_def = np.clip(x + delta_x, 0, width - 1)\n",
    "            y_def = np.clip(y, 0, height - 1)\n",
    "            new_keypoints.extend([x_def, y_def, v])\n",
    "        else:\n",
    "            new_keypoints.extend([x, y, v])\n",
    "    return new_keypoints\n",
    "\n",
    "\n",
    "def generate_wrinkle_points(width, height, num_wrinkles=3, min_distance=80):\n",
    "    \"\"\"Generate randomly distributed wrinkle points with realistic parameters\"\"\"\n",
    "    wrinkle_points = []\n",
    "    attempts = 0\n",
    "    max_attempts = 1000\n",
    "\n",
    "    while len(wrinkle_points) < num_wrinkles and attempts < max_attempts:\n",
    "        x = random.uniform(width * 0.2, width * 0.8)\n",
    "        y = random.uniform(height * 0.2, height * 0.8)\n",
    "\n",
    "        valid = True\n",
    "        for px, py, _, _ in wrinkle_points:\n",
    "            if np.sqrt((x - px) ** 2 + (y - py) ** 2) < min_distance:\n",
    "                valid = False\n",
    "                break\n",
    "\n",
    "        if valid:\n",
    "            intensity = random.uniform(3, 8)\n",
    "            radius = random.uniform(40, 80)\n",
    "            wrinkle_points.append((x, y, intensity, radius))\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    return wrinkle_points\n",
    "\n",
    "\n",
    "def apply_wrinkle_transform(image, wrinkle_intensity=0.3, num_wrinkles=3):\n",
    "    \"\"\"Apply realistic wrinkle transformation to an image\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    wrinkle_points = generate_wrinkle_points(width, height, num_wrinkles)\n",
    "\n",
    "    y_dest, x_dest = np.mgrid[0:height, 0:width]\n",
    "    x_source = x_dest.astype(float)\n",
    "    y_source = y_dest.astype(float)\n",
    "\n",
    "    for wx, wy, intensity, radius in wrinkle_points:\n",
    "        dist = np.sqrt((x_dest - wx) ** 2 + (y_dest - wy) ** 2)\n",
    "        influence = np.exp(-dist ** 2 / (2 * (radius * 1.5) ** 2))\n",
    "\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        radial_factor = intensity * wrinkle_intensity * influence\n",
    "\n",
    "        displacement_x = radial_factor * (\n",
    "                np.cos(angle + dist / radius) * np.sin(dist / radius * 2) +\n",
    "                0.2 * np.sin(2 * angle) * np.exp(-dist / (radius * 0.8))\n",
    "        )\n",
    "\n",
    "        displacement_y = radial_factor * (\n",
    "                np.sin(angle + dist / radius) * np.sin(dist / radius * 2) +\n",
    "                0.2 * np.cos(2 * angle) * np.exp(-dist / (radius * 0.8))\n",
    "        )\n",
    "\n",
    "        x_source += displacement_x\n",
    "        y_source += displacement_y\n",
    "\n",
    "    result = np.zeros_like(image)\n",
    "    for c in range(image.shape[2]):\n",
    "        result[..., c] = map_coordinates(\n",
    "            image[..., c], [y_source, x_source], order=1, mode='constant', cval=255\n",
    "        )\n",
    "\n",
    "    displacement_x = x_source - x_dest\n",
    "    displacement_y = y_source - y_dest\n",
    "\n",
    "    return result.astype(np.uint8), displacement_x, displacement_y\n",
    "\n",
    "\n",
    "def deform_keypoints_wrinkle(keypoints, displacement_x, displacement_y, width, height):\n",
    "    \"\"\"Apply wrinkle transformation to keypoints\"\"\"\n",
    "    new_keypoints = []\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i], keypoints[i + 1], keypoints[i + 2]\n",
    "        if v > 0:\n",
    "            x = np.clip(x, 0, width - 1)\n",
    "            y = np.clip(y, 0, height - 1)\n",
    "\n",
    "            x_int, y_int = int(x), int(y)\n",
    "            x_int = min(x_int, displacement_x.shape[1] - 1)\n",
    "            y_int = min(y_int, displacement_x.shape[0] - 1)\n",
    "\n",
    "            dx = displacement_x[y_int, x_int]\n",
    "            dy = displacement_y[y_int, x_int]\n",
    "\n",
    "            x_deformed = np.clip(x + dx, 0, width - 1)\n",
    "            y_deformed = np.clip(y + dy, 0, height - 1)\n",
    "            new_keypoints.extend([x_deformed, y_deformed, v])\n",
    "        else:\n",
    "            new_keypoints.extend([x, y, v])\n",
    "    return new_keypoints\n",
    "\n",
    "\n",
    "def normalize_heatmap(hm):\n",
    "    \"\"\"Normalize heatmap values\"\"\"\n",
    "    return (hm - np.min(hm)) / (np.max(hm) - np.min(hm) + 1e-8)\n",
    "\n",
    "\n",
    "class KeypointDetector(nn.Module):\n",
    "    def __init__(self, backbone='resnet18', pretrained=True):\n",
    "        super().__init__()\n",
    "        if backbone == 'resnet18':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "            else:\n",
    "                self.backbone = models.resnet18(weights=None)\n",
    "            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "            backbone_features = 512\n",
    "        else:\n",
    "            raise ValueError(f\"Backbone '{backbone}' not supported.\")\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(backbone_features, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, 2, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        heatmaps = self.upsample(features)\n",
    "        return heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478fafce907f797a",
   "metadata": {},
   "source": [
    "Please fill in the following variables with your custom paths:\n",
    "coco = path to your annotation JSON file,\n",
    "file = path to your dataset,\n",
    "id = identifier of an image from your dataset on which you want to visualize all elements defined in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf13e07bc0daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco =\n",
    "file =\n",
    "id =\n",
    "\n",
    "Z = KeypointDataset(coco_json=coco, img_dir=file)\n",
    "\n",
    "id_image = Z.id_to_image_id[id]\n",
    "filename = Z.img_id_to_file[id_image]\n",
    "full_name = file + '/' + filename\n",
    "keypoints = Z.id_to_keypoints[id]\n",
    "\n",
    "x_black_cell, y_black_cell, x_white_cell, y_white_cell = separate_keypoints_by_visibility(keypoints)\n",
    "\n",
    "img = Image.open(full_name).convert(\"RGB\")\n",
    "img_np = np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1706609b1fc4d",
   "metadata": {},
   "source": [
    "First, let's visualize the overlay of annotations on the image. This will serve as a foundation for building our ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9528ad2b35fa90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "output_pdf_path1 = 'Visualization_annotations.pdf'\n",
    "\n",
    "with PdfPages(output_pdf_path1) as pdf:\n",
    "    img = mpimg.imread(full_name)\n",
    "    ax.imshow(img, cmap=\"grey\")\n",
    "    ax.set_title('Visualization of Annotations with Cell Polarity Distinctions', fontsize=14, pad=20)\n",
    "\n",
    "    ax.scatter(x_black_cell, y_black_cell, c='red', s=8, label='Black Cells', alpha=0.8)\n",
    "    ax.scatter(x_white_cell, y_white_cell, c='blue', s=8, label='White Cells', alpha=0.8)\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cd24cbb17d194",
   "metadata": {},
   "source": [
    "Next, depending on your dataset size, you may have performed offline transformations using Albumentations, expanding your dataset size without duplicating the original images. Here is the visualization of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52082b07d1cd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_x = keypoints[::3]\n",
    "keypoints_y = keypoints[1::3]\n",
    "keypoints_v = keypoints[2::3]\n",
    "keypoints_xy = [(x, y) for x, y in zip(keypoints_x, keypoints_y)]\n",
    "\n",
    "offline_transformations = {\n",
    "    \"rot1\": A.Compose([A.Rotate(limit=(0, 90), p=1)], keypoint_params=A.KeypointParams(format='xy')),\n",
    "    \"rot2\": A.Compose([A.Rotate(limit=(0, 90), p=1)], keypoint_params=A.KeypointParams(format='xy')),\n",
    "    \"noise\": A.Compose([A.GaussNoise(var_limit=(10.0, 50.0), p=1)]),\n",
    "    \"contrast\": A.Compose([\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.3,\n",
    "            contrast_limit=0.15,\n",
    "            p=1.0\n",
    "        )\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "}\n",
    "\n",
    "output_pdf_path2 = 'Offline_transformations.pdf'\n",
    "create_transformation_visualization(full_name, keypoints_v, keypoints_xy,\n",
    "                                    offline_transformations, output_pdf_path2,\n",
    "                                    _, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf4cec1db2f425",
   "metadata": {},
   "source": [
    "Additionally, during training you had the option to perform online transformations with Albumentations to prevent overfitting, ensuring that the images seen by our model at each epoch are never identical. Here is the visualization of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcbeee0b891443",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_transformations = {\n",
    "    \"online_transformation\": A.Compose([\n",
    "        A.Rotate(limit=15, p=0.85, border_mode=cv2.BORDER_REFLECT),\n",
    "        A.HorizontalFlip(p=0.15),\n",
    "        A.VerticalFlip(p=0),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.2,\n",
    "            rotate_limit=15,\n",
    "            border_mode=cv2.BORDER_REFLECT,\n",
    "            p=0\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.3,\n",
    "            contrast_limit=0.3,\n",
    "            p=0.7\n",
    "        ),\n",
    "        A.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.1,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomGamma(gamma_limit=(60, 140), p=1),\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=30,\n",
    "            sat_shift_limit=40,\n",
    "            val_shift_limit=30,\n",
    "            p=0.7\n",
    "        ),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
    "        ], p=0.4),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=3, p=0.3),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "        ], p=0.3),\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "}\n",
    "\n",
    "output_pdf_path3 = 'Online_transformations_4.pdf'\n",
    "create_transformation_visualization(full_name, keypoints_v, keypoints_xy,\n",
    "                                    online_transformations, output_pdf_path3,\n",
    "                                    _, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b166ed697c879c",
   "metadata": {},
   "source": [
    "Next, you likely applied a transformation simulating the curvature of a datamatrix code, here is the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932ad3148081f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(full_name).convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "\n",
    "curvature = 0.2\n",
    "deformed_img_np = apply_curvature_transform(img_np, curvature)\n",
    "new_keypoints = deform_keypoints_curvature(keypoints, img_np.shape[0], img_np.shape[1], curvature)\n",
    "\n",
    "x_black, y_black, x_white, y_white = separate_keypoints_by_visibility(new_keypoints)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), dpi=300)\n",
    "\n",
    "axs[0].imshow(img_np)\n",
    "axs[0].set_title('Original Image', fontsize=14, pad=15)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(deformed_img_np)\n",
    "axs[1].set_title('Curvature Transformed Image', fontsize=14, pad=15)\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(deformed_img_np)\n",
    "axs[2].scatter(x_black, y_black, c='red', label='Black Keypoints (v=2)', s=12) \n",
    "axs[2].scatter(x_white, y_white, c='blue', label='White Keypoints (vâ‰ 2)', s=12, edgecolors='black')  \n",
    "axs[2].set_title('Transformed Image with Keypoints', fontsize=14, pad=15)\n",
    "axs[2].legend(loc='upper right', fontsize=10)\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "output_pdf_path4 = 'Curvature.pdf'\n",
    "with PdfPages(output_pdf_path4) as pdf:\n",
    "\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2b1e62444d906",
   "metadata": {},
   "source": [
    "Finally, you likely applied a transformation simulating the crumpling of a datamatrix code, here is the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8fe234eb449e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrinkle_intensity = 0.3\n",
    "num_wrinkles = 3\n",
    "deformed_img_np, displacement_x, displacement_y = apply_wrinkle_transform(img_np, wrinkle_intensity, num_wrinkles)\n",
    "new_keypoints = deform_keypoints_wrinkle(keypoints, displacement_x, displacement_y, img_np.shape[1], img_np.shape[0])\n",
    "\n",
    "x_black_orig, y_black_orig, x_white_orig, y_white_orig = separate_keypoints_by_visibility(keypoints)\n",
    "x_black_new, y_black_new, x_white_new, y_white_new = separate_keypoints_by_visibility(new_keypoints)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), dpi=300)\n",
    "\n",
    "\n",
    "axs[0].imshow(img_np)\n",
    "axs[0].set_title('Original Image', fontsize=14, pad=15)\n",
    "axs[0].axis('off')\n",
    "\n",
    "\n",
    "axs[1].imshow(deformed_img_np)\n",
    "axs[1].set_title('Crumpled Image', fontsize=14, pad=15)\n",
    "axs[1].axis('off')\n",
    "\n",
    "\n",
    "axs[2].imshow(deformed_img_np)\n",
    "axs[2].scatter(x_black_new, y_black_new, c='red', label='Black Cells (v=2)', s=12)  \n",
    "axs[2].scatter(x_white_new, y_white_new, c='blue', label='White Cells (v=1)', s=12, edgecolors='black')  \n",
    "axs[2].legend(loc='upper right', fontsize=10)\n",
    "axs[2].set_title('Crumpled Image + Keypoints', fontsize=14, pad=15)\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "output_pdf_path5 = 'Crumpling.pdf'\n",
    "with PdfPages(output_pdf_path5) as pdf:\n",
    "\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3804e84c658fbd",
   "metadata": {},
   "source": [
    "On the other hand, you had to build a ground truth using Gaussians which enabled the progressive construction of predicted heatmaps during training by minimizing the loss applied to the predicted heatmaps and ground truth. Additionally, you had to construct a binary heatmap corresponding to the binarization of the ground truth, which allowed you to apply associative embedding. Here is the visualization of the ground truth and binary heatmaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875328209bf1412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = sorted([f for f in os.listdir(file) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))])\n",
    "image_name = train_img_list[0] if train_img_list else filename\n",
    "base_name = os.path.splitext(image_name)[0]\n",
    "\n",
    "train_dataset = KeypointDataset(\n",
    "    coco_json=coco,\n",
    "    img_dir=file,\n",
    "    img_list=[image_name]\n",
    ")\n",
    "sigma = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "def f(d):\n",
    "    return np.exp(-(d ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "\n",
    "lim = f(1.5 * sigma)\n",
    "\n",
    "images, targets = next(iter(train_loader))\n",
    "image_tensor = images[0]\n",
    "heatmap_black_tensor = targets[0]\n",
    "heatmap_white_tensor = targets[1]\n",
    "\n",
    "image = image_tensor.permute(1, 2, 0).numpy()\n",
    "heatmap_black = heatmap_black_tensor.squeeze().numpy()\n",
    "heatmap_white = heatmap_white_tensor.squeeze().numpy()\n",
    "\n",
    "heatmap_black_norm = normalize_heatmap(heatmap_black)\n",
    "heatmap_white_norm = normalize_heatmap(heatmap_white)\n",
    "\n",
    "H, W = heatmap_black_norm.shape\n",
    "binary_heatmap_black = (heatmap_black >= lim).astype(float)\n",
    "binary_heatmap_white = (heatmap_white >= lim).astype(float)\n",
    "\n",
    "overlay_rgb_norm = np.zeros((H, W, 3))\n",
    "overlay_rgb_norm[..., 0] = heatmap_black_norm  \n",
    "overlay_rgb_norm[..., 2] = heatmap_white_norm  \n",
    "overlay_rgb_binary = np.zeros((H, W, 3))\n",
    "overlay_rgb_binary[..., 0] = binary_heatmap_black  \n",
    "overlay_rgb_binary[..., 2] = binary_heatmap_white  \n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title('Original Image', fontsize=14, pad=15)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(overlay_rgb_norm)\n",
    "axs[1].set_title('Overlay: Normalized Heatmaps', fontsize=14, pad=15)\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(overlay_rgb_binary)\n",
    "axs[2].set_title('Overlay: Binary Heatmaps', fontsize=14, pad=15)\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "output_path6 = f'heatmaps.pdf'\n",
    "plt.savefig(output_path6, format='pdf', dpi=300)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83006f763d1fc672",
   "metadata": {},
   "source": [
    "Finally, before starting training, the predicted heatmaps are initialized by the weights loaded from a ResNet 18, 34, or 50 backbone. Here is the visualization of the backbone output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710dc0508ba8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeypointDetector(backbone='resnet18', pretrained=True)\n",
    "predicted_heatmaps = model(image_tensor.unsqueeze(0))\n",
    "\n",
    "heatmap_np = predicted_heatmaps.squeeze().cpu().detach().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  \n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title('Original Image', fontsize=12, pad=15)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(heatmap_np[0], cmap='hot')\n",
    "axs[1].set_title('Predicted Heatmap Black\\n(Channel 0)', fontsize=12, pad=15)\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(heatmap_np[1], cmap='gray')\n",
    "axs[2].set_title('Predicted Heatmap White\\n(Channel 1)', fontsize=12, pad=15)\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "output_path7 = f'Backbone.pdf'\n",
    "plt.savefig(output_path7, format='pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"Saved to: {output_path7}\")\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688b66b5a39bc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
